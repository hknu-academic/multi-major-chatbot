"""
============================================================
ğŸ“ í•œê²½êµ­ë¦½ëŒ€í•™êµ ë‹¤ì „ê³µ ì•ˆë‚´ AIì±—ë´‡
============================================================
ë²„ì „: 3.1 (ì„¤ì • íŒŒì¼ ë¶„ë¦¬)
íŠ¹ì§•:
- Semantic Routerë¡œ ì˜ë¯¸ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
- ì„¤ì • íŒŒì¼ ë¶„ë¦¬ (config/*.yaml)
- ë©”ì‹œì§€, ë§¤í•‘, ì„¤ì • ì™¸ë¶€í™”
============================================================

ğŸ”§ ì„¤ì¹˜ í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬:
pip install semantic-router sentence-transformers pyyaml

============================================================
"""

import streamlit as st
from google import genai
import pandas as pd
from streamlit_option_menu import option_menu 
from datetime import datetime
import os
import yaml
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import uuid
import re
import logging

# ============================================================
# ğŸ“Œ ì„¤ì • íŒŒì¼ ë¡œë“œ
# ============================================================

def load_yaml_config(filename):
    """YAML ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    config_path = os.path.join('config', filename)
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    return {}

# ì„¤ì • íŒŒì¼ ë¡œë“œ
MESSAGES = load_yaml_config('messages.yaml')
MAPPINGS = load_yaml_config('mappings.yaml')
SETTINGS = load_yaml_config('settings.yaml')

# ============================================================
# ğŸ“Œ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ìƒìˆ˜
# ============================================================

CONTACT_MESSAGE = "ê¸°ë³¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤." 

# ë¬¸ì˜ ë©”ì‹œì§€
CONTACT_MESSAGE = MESSAGES.get('contact', {}).get('default', 
    CONTACT_MESSAGE)

# ì‹ ì²­ ê¸°ê°„ ì •ë³´
APP_PERIOD = MESSAGES.get('application_period', {})
APP_PERIOD_TITLE = APP_PERIOD.get('title', "ğŸ“… ë‹¤ì „ê³µ ì‹ ì²­ ê¸°ê°„ ì•ˆë‚´")
APP_PERIOD_INTRO = APP_PERIOD.get('intro', "ë‹¤ì „ê³µ ì‹ ì²­ì€ **ë§¤ í•™ê¸° 2íšŒ** ì§„í–‰ë©ë‹ˆë‹¤.")
APP_PERIOD_1ST = APP_PERIOD.get('first_semester', "ì „í•™ê¸° **10ì›”** / **12ì›”**")
APP_PERIOD_2ND = APP_PERIOD.get('second_semester', "ì „í•™ê¸° **4ì›”** / **6ì›”**")

# ë§í¬
LINKS = MESSAGES.get('links', {})
ACADEMIC_NOTICE_URL = LINKS.get('academic_notice', "https://www.hknu.ac.kr/kor/562/subview.do")

# ì—ëŸ¬ ë©”ì‹œì§€
ERRORS = MESSAGES.get('errors', {})

# ê²½ë¡œ
PATHS = SETTINGS.get('paths', {})
CURRICULUM_IMAGES_PATH = PATHS.get('curriculum_images', "images/curriculum")

# ì•± ì„¤ì •
APP_CONFIG = SETTINGS.get('app', {})
APP_TITLE = APP_CONFIG.get('title', "ğŸ“ í•œê²½êµ­ë¦½ëŒ€ ìœ ì—°í•™ì‚¬ì œë„(ë‹¤ì „ê³µ) ì•ˆë‚´")

# ì˜ˆì‹œ ì§ˆë¬¸
EXAMPLE_QUESTIONS = SETTINGS.get('example_questions', [
    "ë³µìˆ˜ì „ê³µ ì‹ ì²­ ìê²©ì´ ë­ì•¼?",
    "ì‹ ì²­ ê¸°ê°„ì€ ì–¸ì œì¸ê°€ìš”?",
    "ë¶€ì „ê³µì´ë‘ ë³µìˆ˜ì „ê³µ ì°¨ì´ê°€ ë­ì•¼?",
    "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ê°€ ë­ì•¼?"
])

# íƒ€ê²Ÿ ì œë„
TARGET_PROGRAMS = SETTINGS.get('target_programs', ["ë³µìˆ˜ì „ê³µ", "ë¶€ì „ê³µ", "ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ"])

# ë‚œì´ë„ ë§¤í•‘
DIFFICULTY_STARS = MAPPINGS.get('difficulty_stars', {})

def convert_difficulty_to_stars(value):
    """ìˆ«ìë¥¼ ë³„ì ìœ¼ë¡œ ë³€í™˜"""
    if pd.isna(value) or value == '':
        return DIFFICULTY_STARS.get('default', 'â­â­â­')
    if isinstance(value, str) and 'â­' in value:
        return value
    try:
        num = int(float(value))
        return DIFFICULTY_STARS.get(num, DIFFICULTY_STARS.get('default', 'â­â­â­'))
    except:
        return DIFFICULTY_STARS.get('default', 'â­â­â­')

# Semantic Router ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
logging.getLogger("semantic_router").setLevel(logging.ERROR)

# === Semantic Router ì„¤ì • ===
SEMANTIC_ROUTER_ENABLED = True  # Falseë¡œ ë³€ê²½í•˜ë©´ ê¸°ì¡´ í‚¤ì›Œë“œ ë°©ì‹ìœ¼ë¡œ ë™ì‘

# Semantic Router import (ë²„ì „ì— ë”°ë¼ ê²½ë¡œê°€ ë‹¤ë¦„)
SEMANTIC_ROUTER_AVAILABLE = False
Route = None
SemanticRouter = None  # 0.1.xì—ì„œëŠ” RouteLayer ëŒ€ì‹  SemanticRouter ì‚¬ìš©
HuggingFaceEncoder = None
LocalIndex = None

try:
    # 0.1.x ë²„ì „ (ìµœì‹ )
    from semantic_router import Route
    from semantic_router.routers import SemanticRouter
    from semantic_router.encoders import HuggingFaceEncoder
    from semantic_router.index import LocalIndex
    SEMANTIC_ROUTER_AVAILABLE = True
    SEMANTIC_ROUTER_VERSION = "0.1.x"
except ImportError:
    try:
        # 0.0.x ë²„ì „ (êµ¬ë²„ì „)
        from semantic_router import Route
        from semantic_router.layer import RouteLayer as SemanticRouter
        from semantic_router.encoders import HuggingFaceEncoder
        SEMANTIC_ROUTER_AVAILABLE = True
        SEMANTIC_ROUTER_VERSION = "0.0.x"
    except ImportError:
        SEMANTIC_ROUTER_AVAILABLE = False
        SEMANTIC_ROUTER_VERSION = None

if not SEMANTIC_ROUTER_AVAILABLE:
    st.warning("âš ï¸ Semantic Routerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ í˜¸í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\ní‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ë¡œ ë™ì‘í•©ë‹ˆë‹¤.\nì„¤ì¹˜: pip install semantic-router sentence-transformers")

# === [AI ì„¤ì •] Gemini API ì—°ê²° ===
GEMINI_API_KEY = "AIzaSyAyBEX3MRQv6q3RhNpznsfuDWKqhAlaGV8"
if not GEMINI_API_KEY:
    st.error("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    st.stop()

client = genai.Client(api_key=GEMINI_API_KEY)

# === í˜ì´ì§€ ì„¤ì • ===
st.set_page_config(
    page_title="ë‹¤ì „ê³µ ì•ˆë‚´ AIì±—ë´‡",
    page_icon="ğŸ“",
    layout="wide",
)

# === Streamlit ë¸Œëœë”© ì œê±° ë° ëª¨ë°”ì¼ ìµœì í™” ===
hide_streamlit_branding = """
<style>
footer {display: none !important;}
#MainMenu {visibility: hidden;}

/* ì‚¬ì´ë“œë°” í† ê¸€ ë²„íŠ¼ì€ ìœ ì§€ */
[data-testid="collapsedControl"] {
    visibility: visible !important;
    display: block !important;
}

.stChatInputContainer {
    position: sticky;
    bottom: 0;
    background: white;
    padding: 0.75rem 0;
    z-index: 999;
    box-shadow: 0 -2px 10px rgba(0,0,0,0.05);
}

.stChatMessage {
    margin-bottom: 0.5rem;
}

@media (max-width: 768px) {
    section[data-testid="stSidebar"] {
        width: 85%;
    }
    .stChatInputContainer {
        padding: 0.5rem;
    }
    .stChatMessage {
        padding: 0.5rem !important;
    }
    .stButton button {
        padding: 0.5rem 1rem;
        font-size: 0.9rem;
    }
}
</style>
"""
st.markdown(hide_streamlit_branding, unsafe_allow_html=True)


# === ìë™ ìŠ¤í¬ë¡¤ í•¨ìˆ˜ ===
def scroll_to_bottom():
    unique_id = str(uuid.uuid4())
    js = f"""
    <script>
        function scrollIntoView() {{
            var messages = window.parent.document.querySelectorAll('[data-testid="stChatMessage"]');
            if (messages.length > 0) {{
                var lastMessage = messages[messages.length - 1];
                lastMessage.scrollIntoView({{behavior: "smooth", block: "end"}});
            }}
        }}
        setTimeout(scrollIntoView, 300);
        setTimeout(scrollIntoView, 500);
    </script>
    """
    st.components.v1.html(js, height=0)


# === ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ===
def initialize_session_state():
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'page' not in st.session_state:
        st.session_state.page = "AIì±—ë´‡ ìƒë‹´"


# ============================================================
# ğŸ“‚ ë°ì´í„° ë¡œë“œ
# ============================================================

@st.cache_data
def load_excel_data(file_path, sheet_name=0):
    """ì—‘ì…€ íŒŒì¼ ë¡œë“œ (ê¸°ë³¸: ì²« ë²ˆì§¸ ì‹œíŠ¸)"""
    try:
        if os.path.exists(file_path):
            result = pd.read_excel(file_path, sheet_name=sheet_name)
            # sheet_name=Noneì¸ ê²½ìš° dict ë°˜í™˜ë˜ë¯€ë¡œ ì²˜ë¦¬
            if isinstance(result, dict):
                # ì²« ë²ˆì§¸ ì‹œíŠ¸ ë°˜í™˜
                first_sheet = list(result.values())[0] if result else pd.DataFrame()
                return first_sheet
            return result
        return pd.DataFrame()
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()


@st.cache_data
def load_program_info():
    df = load_excel_data('data/programs.xlsx')
    if not isinstance(df, pd.DataFrame) or df.empty:
        return {}
    programs = {}
    for _, row in df.iterrows():
        name = row.get('ì œë„ëª…', '')
        if name and pd.notna(name):
            # NaN ê°’ ì²˜ë¦¬ í•¨ìˆ˜
            def safe_get(key, default=''):
                val = row.get(key, default)
                return default if pd.isna(val) else val
            
            programs[name] = {
                'description': safe_get('ì„¤ëª…', ''),
                'qualification': safe_get('ì‹ ì²­ìê²©', ''),
                'credits_general': safe_get('ì´ìˆ˜í•™ì (êµì–‘)', ''),
                'credits_primary': safe_get('ì›ì „ê³µ ì´ìˆ˜í•™ì ', ''),
                'credits_multi': safe_get('ë‹¤ì „ê³µ ì´ìˆ˜í•™ì ', ''),
                'degree': safe_get('í•™ìœ„ê¸° í‘œê¸°', '-'),
                'features': str(safe_get('íŠ¹ì§•', '')).split('\n') if safe_get('íŠ¹ì§•', '') else [],
                'notes': safe_get('ê¸°íƒ€', ''),
                'difficulty': convert_difficulty_to_stars(safe_get('ë‚œì´ë„', '3')),
                'graduation_certification': safe_get('ì¡¸ì—…ì¸ì¦', '-'),
                'graduation_exam': safe_get('ì¡¸ì—…ì‹œí—˜', '-'),
            }
    return programs


@st.cache_data
def load_curriculum_mapping():
    try:
        if os.path.exists('data/curriculum_mapping.xlsx'):
            return pd.read_excel('data/curriculum_mapping.xlsx')
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'íŒŒì¼ëª…'])
    except:
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'íŒŒì¼ëª…'])


@st.cache_data
def load_courses_data():
    try:
        if os.path.exists('data/courses.xlsx'):
            return pd.read_excel('data/courses.xlsx')
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'í•™ë…„', 'í•™ê¸°', 'ì´ìˆ˜êµ¬ë¶„', 'ê³¼ëª©ëª…', 'í•™ì '])
    except:
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'í•™ë…„', 'í•™ê¸°', 'ì´ìˆ˜êµ¬ë¶„', 'ê³¼ëª©ëª…', 'í•™ì '])


@st.cache_data
def load_faq_data():
    df = load_excel_data('data/faq.xlsx')
    if df.empty:
        return []
    return df.to_dict('records')


@st.cache_data
def load_majors_info():
    return load_excel_data('data/majors_info.xlsx')


@st.cache_data
def load_graduation_requirements():
    return load_excel_data('data/graduation_requirements.xlsx')


@st.cache_data
def load_primary_requirements():
    return load_excel_data('data/primary_requirements.xlsx')


# ë°ì´í„° ë¡œë“œ
PROGRAM_INFO = load_program_info()
CURRICULUM_MAPPING = load_curriculum_mapping()
COURSES_DATA = load_courses_data()
FAQ_DATA = load_faq_data()
MAJORS_INFO = load_majors_info()
GRADUATION_REQ = load_graduation_requirements()
PRIMARY_REQ = load_primary_requirements()

# ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
ALL_DATA = {
    'programs': PROGRAM_INFO,
    'curriculum': CURRICULUM_MAPPING,
    'courses': COURSES_DATA,
    'faq': FAQ_DATA,
    'majors': MAJORS_INFO,
    'grad_req': GRADUATION_REQ,
    'primary_req': PRIMARY_REQ,
}


# ============================================================
# ğŸ§  Semantic Router ì„¤ì • (Level 2 í•µì‹¬!)
# ============================================================

# === ì˜ë„ë³„ ì˜ˆì‹œ ë¬¸ì¥ (Semantic Routerìš©) ===
INTENT_UTTERANCES = {
    'QUALIFICATION': [
        "ì‹ ì²­ ìê²©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ì§€ì› ìê²© ì•Œë ¤ì£¼ì„¸ìš”",
        "ëˆ„ê°€ ì‹ ì²­í•  ìˆ˜ ìˆì–´ìš”?",
        "ìê²© ìš”ê±´ì´ ë­ì˜ˆìš”?",
        "ë‚˜ë„ ì‹ ì²­ ê°€ëŠ¥í•´?",
        "ëª‡ í•™ë…„ë¶€í„° í•  ìˆ˜ ìˆì–´ìš”?",
        "2í•™ë…„ì¸ë° ê°€ëŠ¥í•œê°€ìš”?",
        "í•™ì ì´ ë‚®ì•„ë„ ë˜ë‚˜ìš”?",
        "ì¡°ê±´ì´ ì–´ë–»ê²Œ ë¼?",
        "ì‹ ì²­ ì¡°ê±´ ì•Œë ¤ì¤˜",
        "ìê²©ì´ ë˜ëŠ”ì§€ ëª¨ë¥´ê² ì–´",
        "ì´ê±° í•´ë„ ë¼?",
        "ë‚˜ ìê²© ìˆì–´?",
        "ì‹ ì²­ ìê²© ì¡°ê±´",
        "ì§€ì› ê°€ëŠ¥ ì—¬ë¶€",
    ],
    
    'APPLICATION_PERIOD': [
        "ì‹ ì²­ ê¸°ê°„ì´ ì–¸ì œì˜ˆìš”?",
        "ì–¸ì œ ì‹ ì²­í•´ìš”?",
        "ë§ˆê°ì¼ì´ ì–¸ì œì•¼?",
        "ì§€ì› ê¸°ê°„ ì•Œë ¤ì£¼ì„¸ìš”",
        "ì–¸ì œê¹Œì§€ ì‹ ì²­í•  ìˆ˜ ìˆì–´ìš”?",
        "ì ‘ìˆ˜ ê¸°ê°„ì´ ì–´ë–»ê²Œ ë¼?",
        "ëª‡ ì›”ì— ì‹ ì²­í•´?",
        "ì‹ ì²­ ì‹œì‘ì¼ì´ ì–¸ì œì•¼?",
        "ê¸°ê°„ì´ ì–¼ë§ˆë‚˜ ë‚¨ì•˜ì–´?",
        "ì§€ê¸ˆ ì‹ ì²­ ê°€ëŠ¥í•´?",
        "ì´ë²ˆ í•™ê¸° ì‹ ì²­ ê¸°ê°„",
        "ë‹¤ìŒ í•™ê¸° ì‹ ì²­ì€ ì–¸ì œ?",
        "ì‹ ì²­ ì¼ì • ì•Œë ¤ì¤˜",
        "ì ‘ìˆ˜ ë§ˆê°ì¼",
        "ì–¸ì œë¶€í„° ì–¸ì œê¹Œì§€ì•¼?",
    ],
    
    'APPLICATION_METHOD': [
        "ì‹ ì²­ ë°©ë²•ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ì–´ë–»ê²Œ ì‹ ì²­í•´ìš”?",
        "ì‹ ì²­ ì ˆì°¨ ì•Œë ¤ì£¼ì„¸ìš”",
        "ì§€ì›í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´?",
        "ì‹ ì²­í•˜ëŠ” ë²• ì•Œë ¤ì¤˜",
        "ì–´ë””ì„œ ì‹ ì²­í•´?",
        "ì˜¨ë¼ì¸ìœ¼ë¡œ ì‹ ì²­ ê°€ëŠ¥í•´?",
        "ì‹ ì²­ì„œ ì–´ë””ì„œ ë°›ì•„?",
        "ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë¼?",
        "ì§€ì› ë°©ë²•ì´ ë­ì•¼?",
        "ì‹ ì²­í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•´?",
        "ì ‘ìˆ˜ ë°©ë²•",
        "ì‹ ì²­ í”„ë¡œì„¸ìŠ¤",
        "ì§€ì› ì ˆì°¨ ì„¤ëª…í•´ì¤˜",
        "ì–´ë””ë¡œ ê°€ì•¼í•´?",
    ],
    
    'CANCEL': [
        "í¬ê¸°í•˜ê³  ì‹¶ì–´ìš”",
        "ì·¨ì†Œ ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
        "ì² íšŒí•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´?",
        "ê·¸ë§Œë‘ê³  ì‹¶ì–´",
        "ì¤‘ë‹¨í•˜ê³  ì‹¶ì€ë°",
        "í¬ê¸° ì‹ ì²­ ì–´ë–»ê²Œ í•´?",
        "ì·¨ì†Œí•  ìˆ˜ ìˆì–´?",
        "í¬ê¸° ê¸°ê°„ì´ ì–¸ì œì•¼?",
        "ì·¨ì†Œ ê°€ëŠ¥í•œê°€ìš”?",
        "ë‹¤ì „ê³µ í¬ê¸°",
        "ë³µìˆ˜ì „ê³µ ì·¨ì†Œ",
        "í¬ê¸°í•˜ë©´ ì–´ë–»ê²Œ ë¼?",
        "ì·¨ì†Œ ì ˆì°¨",
        "í¬ê¸° ë°©ë²•",
        "ì•ˆ í•˜ê³  ì‹¶ì–´",
    ],
    
    'CHANGE': [
        "ë³€ê²½í•˜ê³  ì‹¶ì–´ìš”",
        "ì „ê³µ ë°”ê¾¸ê³  ì‹¶ì–´",
        "ìˆ˜ì •í•  ìˆ˜ ìˆë‚˜ìš”?",
        "ì „í™˜í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´?",
        "ë‹¤ë¥¸ ì „ê³µìœ¼ë¡œ ë³€ê²½",
        "ë³µìˆ˜ì „ê³µì—ì„œ ë¶€ì „ê³µìœ¼ë¡œ ë°”ê¾¸ê³  ì‹¶ì–´",
        "ë³€ê²½ ê°€ëŠ¥í•œê°€ìš”?",
        "ì „ê³µ ë³€ê²½ ë°©ë²•",
        "ìˆ˜ì • ì ˆì°¨",
        "ë°”ê¿€ ìˆ˜ ìˆì–´?",
        "ë³€ê²½ ì‹ ì²­",
        "ì „í™˜ ë°©ë²•",
        "ë‹¤ë¥¸ ê±¸ë¡œ ë°”ê¾¸ê³  ì‹¶ì–´",
    ],
    
    'PROGRAM_COMPARISON': [
        "ë³µìˆ˜ì „ê³µì´ë‘ ë¶€ì „ê³µ ì°¨ì´ê°€ ë­ì•¼?",
        "ë­ê°€ ë‹¤ë¥¸ ê±°ì•¼?",
        "ì°¨ì´ì  ì•Œë ¤ì¤˜",
        "ë¹„êµí•´ì¤˜",
        "ë­ê°€ ë” ì¢‹ì•„?",
        "ì–´ë–¤ ê²Œ ë‚˜ì„ê¹Œ?",
        "ìœµí•©ì „ê³µì´ë‘ ë³µìˆ˜ì „ê³µ ë¹„êµ",
        "ë‘˜ ë‹¤ í•˜ë©´ ì–´ë–»ê²Œ ë¼?",
        "ì°¨ì´ì ì´ ë­ì˜ˆìš”?",
        "ë¹„êµí•´ì„œ ì„¤ëª…í•´ì¤˜",
        "ë­ê°€ ìœ ë¦¬í•´?",
        "ë‘˜ ì¤‘ì— ë­ê°€ ì¢‹ì•„?",
        "ì¥ë‹¨ì  ë¹„êµ",
    ],
    
    'CREDIT_INFO': [
        "í•™ì ì´ ëª‡ í•™ì ì´ì•¼?",
        "ì´ìˆ˜ í•™ì  ì•Œë ¤ì¤˜",
        "ì¡¸ì—…í•˜ë ¤ë©´ ëª‡ í•™ì  í•„ìš”í•´?",
        "ë³¸ì „ê³µ í•™ì ì´ ì¤„ì–´ë“¤ì–´?",
        "í•™ì  ë³€í™” ì•Œë ¤ì¤˜",
        "ì´ í•™ì ì´ ì–´ë–»ê²Œ ë¼?",
        "ì „í•„ ëª‡ í•™ì ì´ì•¼?",
        "ì „ì„  í•™ì ì€?",
        "êµì–‘ í•™ì ì€ ì–´ë–»ê²Œ ë¼?",
        "í•™ì  ìš”ê±´",
        "ì¡¸ì—… ìš”ê±´ í•™ì ",
        "í•„ìš”í•œ í•™ì  ìˆ˜",
        "ì´ìˆ˜í•´ì•¼ í•˜ëŠ” í•™ì ",
    ],
    
    'PROGRAM_INFO': [
        "ë³µìˆ˜ì „ê³µì´ ë­ì•¼?",
        "ë¶€ì „ê³µì´ ë­”ê°€ìš”?",
        "ìœµí•©ì „ê³µ ì„¤ëª…í•´ì¤˜",
        "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ê°€ ë­ì˜ˆìš”?",
        "ì—°ê³„ì „ê³µì´ ë­ì§€?",
        "ì´ê²Œ ë­ì•¼?",
        "ì•Œë ¤ì¤˜",
        "ì„¤ëª…í•´ì¤˜",
        "ë¬´ìŠ¨ ì œë„ì•¼?",
        "ì–´ë–¤ ê±´ê°€ìš”?",
        "ì†Œë‹¨ìœ„ì „ê³µì´ ë­ì•¼?",
        "ìœµí•©ë¶€ì „ê³µ ì„¤ëª…",
        "ì œë„ ì„¤ëª…í•´ì¤˜",
    ],
    
    'COURSE_SEARCH': [
        "ì–´ë–¤ ê³¼ëª© ë“¤ì–´ì•¼ í•´?",
        "ì»¤ë¦¬í˜ëŸ¼ ì•Œë ¤ì¤˜",
        "ìˆ˜ì—… ë­ ë“¤ì–´?",
        "ê³¼ëª© ë¦¬ìŠ¤íŠ¸ ë³´ì—¬ì¤˜",
        "ë­ ë°°ì›Œ?",
        "êµê³¼ëª© ì•Œë ¤ì¤˜",
        "ê°•ì˜ ë­ ìˆì–´?",
        "í•„ìˆ˜ ê³¼ëª©ì´ ë­ì•¼?",
        "ì„ íƒ ê³¼ëª©ì€?",
        "ì´ìˆ˜ ê³¼ëª© ëª©ë¡",
        "ê³¼ëª© ì¶”ì²œí•´ì¤˜",
        "ì–´ë–¤ ê°•ì˜ ë“¤ì–´ì•¼ í•´?",
    ],
    
    'CONTACT_SEARCH': [
        "ì—°ë½ì²˜ ì•Œë ¤ì¤˜",
        "ì „í™”ë²ˆí˜¸ê°€ ë­ì•¼?",
        "ë¬¸ì˜ ì–´ë””ë¡œ í•´?",
        "ì‚¬ë¬´ì‹¤ ì–´ë””ì•¼?",
        "ë‹´ë‹¹ì ì—°ë½ì²˜",
        "ì–´ë””ë¡œ ì „í™”í•´?",
        "ë¬¸ì˜ì²˜ ì•Œë ¤ì¤˜",
        "í™ˆí˜ì´ì§€ ì£¼ì†Œ",
        "ìœ„ì¹˜ê°€ ì–´ë””ì•¼?",
        "ì—°ë½í•  ê³³",
    ],
    
    'RECOMMENDATION': [
        "ë­ê°€ ì¢‹ì„ê¹Œ?",
        "ì¶”ì²œí•´ì¤˜",
        "ì–´ë–¤ ê²Œ ì¢‹ì•„?",
        "ë‚˜í•œí…Œ ë§ëŠ” ê±° ë­ì•¼?",
        "ë­ í•´ì•¼ í• ê¹Œ?",
        "ê³ ë¯¼ì´ì•¼ ë­ í• ì§€",
        "ì–´ë–¤ ê±¸ ì„ íƒí•´ì•¼ í• ê¹Œ?",
        "ì¶”ì²œ ì¢€ í•´ì¤˜",
        "ë‚˜í•œí…Œ ì–´ë–¤ ê²Œ ë§ì•„?",
        "ë­ê°€ ìœ ë¦¬í• ê¹Œ?",
        "ê³¨ë¼ì¤˜",
        "ì„ íƒ ë„ì™€ì¤˜",
        "ë­ í•˜ë©´ ì¢‹ì„ê¹Œ?",
        "ì¡°ì–¸ ì¢€ í•´ì¤˜",
    ],
    
    'GREETING': [
        "ì•ˆë…•",
        "ì•ˆë…•í•˜ì„¸ìš”",
        "í•˜ì´",
        "hello",
        "hi",
        "ë°˜ê°€ì›Œ",
        "ì²˜ìŒì´ì•¼",
        "ì‹œì‘",
        "ì•ˆë…•!",
        "í—¬ë¡œ",
    ],
    
    # ğŸš« ë²”ìœ„ ì™¸ ì§ˆë¬¸ (ë‹¤ì „ê³µê³¼ ë¬´ê´€í•œ ì§ˆë¬¸)
    'OUT_OF_SCOPE': [
        "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?",
        "ë§›ì§‘ ì¶”ì²œí•´ì¤˜",
        "ì˜í™” ì¶”ì²œí•´ì¤˜",
        "ê²Œì„ ì¶”ì²œí•´ì¤˜",
        "ì—°ì•  ìƒë‹´ í•´ì¤˜",
        "ì·¨ì—… ì–´ë–»ê²Œ í•´?",
        "ê³µëª¨ì „ ì¶”ì²œí•´ì¤˜",
        "ë™ì•„ë¦¬ ì¶”ì²œí•´ì¤˜",
        "ê¸°ìˆ™ì‚¬ ì‹ ì²­ ì–´ë–»ê²Œ í•´?",
        "ì¥í•™ê¸ˆ ì–´ë–»ê²Œ ë°›ì•„?",
        "í•™ì‹ ë©”ë‰´ ë­ì•¼?",
        "ë„ì„œê´€ ëª‡ì‹œê¹Œì§€ í•´?",
        "ì…”í‹€ë²„ìŠ¤ ì‹œê°„í‘œ ì•Œë ¤ì¤˜",
        "ìˆ˜ê°•ì‹ ì²­ ì–´ë–»ê²Œ í•´?",
        "ì„±ì  ì •ì • ë°©ë²•",
        "íœ´í•™ ì‹ ì²­ ë°©ë²•",
        "ì¡¸ì—… ìš”ê±´ ë­ì•¼?",
        "êµí™˜í•™ìƒ ì–´ë–»ê²Œ ê°€?",
        "ì¸í„´ ì–´ë–»ê²Œ êµ¬í•´?",
        "ìê¸°ì†Œê°œì„œ ì¨ì¤˜",
        "ì´ë ¥ì„œ ë´ì¤˜",
        "ì½”ë”© ì•Œë ¤ì¤˜",
        "íŒŒì´ì¬ ê°€ë¥´ì³ì¤˜",
        "ìˆ˜í•™ ë¬¸ì œ í’€ì–´ì¤˜",
        "ì˜ì–´ ë²ˆì—­í•´ì¤˜",
        "ê³¼ì œ í•´ì¤˜",
        "ë ˆí¬íŠ¸ ì¨ì¤˜",
        "ë„ˆ ëˆ„êµ¬ì•¼?",
        "AIì•¼?",
        "ì‚¬ëŒì´ì•¼?",
    ],
    
    # ğŸš« ìš•ì„¤/ë¹„ì†ì–´ ì°¨ë‹¨
    'BLOCKED': [
        "ì‹œë°œ", "ì”¨ë°œ", "ã……ã…‚", "ã…†ã…‚", "ì”¨ë¹¨", "ì‹œë¹¨",
        "ë³‘ì‹ ", "ã…‚ã……", "ë³‘ë”±", "ë¸…ì‹ ",
        "ì§€ë„", "ã…ˆã„¹", "ì§€ëŸ´",
        "ê°œìƒˆë¼", "ê°œìƒ‰ë¼", "ê°œì„¸ë¼", "ã„±ã……ã„²",
        "êº¼ì ¸", "ë‹¥ì³", "ì£½ì–´", "ë’¤ì ¸",
        "ë¯¸ì¹œ", "ë¯¸ì³¤", "ã…ã…Š", "ë¯¸ì¹œë†ˆ", "ë¯¸ì¹œë…„",
        "ì”¹", "ã…†", "ì”¹ìƒˆ", "ì”¹ë†ˆ",
        "ì¡´ë‚˜", "ì¡¸ë¼", "ã…ˆã„´",
        "ì• ë¯¸", "ì• ë¹„", "ì— ì°½", "ì•°ì°½",
        "ì¢†", "ã…ˆê°™", "ì¢ƒ",
        "ê±¸ë ˆ", "ì°½ë…€", "ë³´ì§€", "ìì§€",
        "fuck", "shit", "damn", "bitch",
        "ì…", "ì—¿ë¨¹ì–´", "ì—¿ì´ë‚˜", "ì¢‡ê¹Œ",
    ],
}

# === ê¸°ì¡´ í‚¤ì›Œë“œ (í´ë°±ìš©) ===
INTENT_KEYWORDS = {
    'QUALIFICATION': [
        'ì‹ ì²­ìê²©', 'ì§€ì›ìê²©', 'ìê²©ìš”ê±´', 'ì‹ ì²­ìš”ê±´', 'ìê²©ì¡°ê±´',
        'ìê²©ì´ì–´ë–»ê²Œ', 'ìê²©ì€', 'ëˆ„ê°€ì‹ ì²­', 'ì‹ ì²­í• ìˆ˜ìˆ', 'ì§€ì›í• ìˆ˜ìˆ',
        'ìê²©ì´ë­', 'ìê²©ì•Œë ¤', 'ìê²©ìš”ê±´ì´', 'ì‹ ì²­ìê²©ì´', 'ìê²©ì´ì–´ë–»ê²Œë¼',
        'ìê²©ì–´ë–»ê²Œ', 'ëˆ„ê°€í• ìˆ˜ìˆ', 'ì‹ ì²­ì¡°ê±´', 'ì§€ì›ì¡°ê±´', 'ì¡°ê±´ì´ë­',
        'ìê²©ì¡°ê±´ì´', 'ì‹ ì²­ê°€ëŠ¥', 'ì§€ì›ê°€ëŠ¥'
    ],
    'APPLICATION_PERIOD': [
        'ì‹ ì²­ê¸°ê°„', 'ì§€ì›ê¸°ê°„', 'ì ‘ìˆ˜ê¸°ê°„', 'ì–¸ì œì‹ ì²­', 'ì–¸ì œì§€ì›',
        'ì‹ ì²­ì€ì–¸ì œ', 'ì§€ì›ì€ì–¸ì œ', 'ì‹ ì²­ì–¸ì œ', 'ê¸°ê°„ì´ì–¸ì œ', 'ê¸°ê°„ì•Œë ¤',
        'ë§ˆê°ì¼', 'ì‹œì‘ì¼', 'ì¢…ë£Œì¼', 'ì ‘ìˆ˜ì¼', 'ì‹ ì²­ì¼', 'ì–¸ì œê¹Œì§€',
        'ê¸°ê°„ì´ì–´ë–»ê²Œ', 'ëª‡ì›”', 'ì–¸ì œë¶€í„°', 'ì–¸ì œí•´'
    ],
    'APPLICATION_METHOD': [
        'ì‹ ì²­ë°©ë²•', 'ì§€ì›ë°©ë²•', 'ì‹ ì²­ì ˆì°¨', 'ì§€ì›ì ˆì°¨', 'ì–´ë–»ê²Œì‹ ì²­',
        'ì–´ë–»ê²Œì§€ì›', 'ì‹ ì²­ì–´ë–»ê²Œ', 'ì ˆì°¨ê°€ì–´ë–»ê²Œ', 'ë°©ë²•ì•Œë ¤',
        'ì‹ ì²­í•˜ëŠ”ë²•', 'ì§€ì›í•˜ëŠ”ë²•', 'ì‹ ì²­í•˜ë ¤ë©´', 'ì§€ì›í•˜ë ¤ë©´',
        'ì–´ë””ì„œì‹ ì²­', 'ì–´ë””ì„œì§€ì›', 'ì ˆì°¨ì•Œë ¤', 'ë°©ë²•ì´ë­'
    ],
    'CANCEL': [
        'í¬ê¸°', 'ì·¨ì†Œ', 'ì² íšŒ', 'ê·¸ë§Œ', 'ì¤‘ë‹¨', 'ì·¨ì†Œë°©ë²•', 'í¬ê¸°ë°©ë²•',
        'ì·¨ì†Œí•˜ë ¤ë©´', 'í¬ê¸°í•˜ë ¤ë©´', 'ì·¨ì†Œí• ìˆ˜ìˆ', 'í¬ê¸°í• ìˆ˜ìˆ',
        'ì·¨ì†Œì–¸ì œ', 'í¬ê¸°ì–¸ì œ', 'ì·¨ì†Œê¸°ê°„', 'í¬ê¸°ê¸°ê°„'
    ],
    'CHANGE': [
        'ë³€ê²½', 'ìˆ˜ì •', 'ë°”ê¾¸', 'ì „í™˜', 'ë³€ê²½ë°©ë²•', 'ë³€ê²½í•˜ë ¤ë©´',
        'ë°”ê¾¸ë ¤ë©´', 'ì „í™˜í•˜ë ¤ë©´', 'ë³€ê²½í• ìˆ˜ìˆ', 'ë°”ê¿€ìˆ˜ìˆ'
    ],
    'PROGRAM_COMPARISON': [
        'ì°¨ì´', 'ë¹„êµ', 'vs', 'ë‹¤ë¥¸ì ', 'ë­ê°€ë‹¬ë¼', 'ì–´ë–»ê²Œë‹¬ë¼',
        'ë¬´ìŠ¨ì°¨ì´', 'ë­ê°€ë‹¤ë¥¸', 'ì°¨ì´ì ', 'ë¹„êµí•´ì¤˜', 'ë­ê°€ì¢‹'
    ],
    'CREDIT_INFO': [
        'í•™ì ', 'ì´ìˆ˜í•™ì ', 'ì¡¸ì—…ìš”ê±´', 'í•„ìš”í•œí•™ì ', 'ëª‡í•™ì ', 
        'ì¡¸ì—…í•™ì ', 'í•™ì ì´', 'ë³€í•´', 'ì¤„ì–´', 'ëŠ˜ì–´', 'í•™ì ë³€í™”',
        'ë³¸ì „ê³µí•™ì ', 'ë‹¤ì „ê³µí•™ì ', 'ì´í•™ì '
    ],
    'PROGRAM_INFO': [
        'ë­ì•¼', 'ë¬´ì—‡', 'ë­”ê°€ìš”', 'ë­ì—ìš”', 'ì•Œë ¤ì¤˜', 'ì„¤ëª…',
        'ë¬´ì—‡ì¸ê°€', 'ì´ë­ì•¼', 'ê°€ë­ì•¼', 'ì€ë­', 'ëŠ”ë­'
    ],
    'COURSE_SEARCH': [
        'ê³¼ëª©', 'ìˆ˜ì—…', 'ê°•ì˜', 'ì»¤ë¦¬í˜ëŸ¼', 'êµìœ¡ê³¼ì •', 'ì´ìˆ˜ê³¼ëª©',
        'ë­ë°°ì›Œ', 'ë­ë“£', 'ê³¼ëª©ë¦¬ìŠ¤íŠ¸', 'ê³¼ëª©ì•Œë ¤', 'ê°•ì˜ì•Œë ¤',
        'êµê³¼ëª©', 'ê³¼ëª©ì¶”ì²œ'
    ],
    'CONTACT_SEARCH': [
        'ì—°ë½ì²˜', 'ì „í™”ë²ˆí˜¸', 'ë¬¸ì˜', 'ë²ˆí˜¸', 'ì‚¬ë¬´ì‹¤',
        'ì–´ë””ìˆ', 'ìœ„ì¹˜', 'ì „í™”', 'í™ˆí˜ì´ì§€', 'ì‚¬ì´íŠ¸'
    ],
    'RECOMMENDATION': [
        'ì¶”ì²œ', 'ë­í• ê¹Œ', 'ì„ íƒ', 'ê³ ë¯¼', 'ì¢‹ì„ê¹Œ', 'ì–´ë–¤ê²Œì¢‹',
        'ì¶”ì²œí•´ì¤˜', 'ê³¨ë¼ì¤˜', 'ë­ê°€ì¢‹ì•„', 'ì–´ë–¤ê±¸', 'ë­í•´ì•¼'
    ],
    'GREETING': [
        'ì•ˆë…•', 'í•˜ì´', 'hello', 'hi', 'ë°˜ê°€', 'ì²˜ìŒ', 'ì‹œì‘'
    ],
    # ğŸš« ë²”ìœ„ ì™¸ ì§ˆë¬¸
    'OUT_OF_SCOPE': [
        'ë‚ ì”¨', 'ë§›ì§‘', 'ì˜í™”', 'ê²Œì„', 'ì—°ì• ', 'ì·¨ì—…', 'ê³µëª¨ì „', 'ë™ì•„ë¦¬',
        'ê¸°ìˆ™ì‚¬', 'ì¥í•™ê¸ˆ', 'í•™ì‹', 'ë„ì„œê´€', 'ì…”í‹€', 'ë²„ìŠ¤', 'ìˆ˜ê°•ì‹ ì²­',
        'ì„±ì ì •ì •', 'íœ´í•™', 'êµí™˜í•™ìƒ', 'ì¸í„´', 'ìì†Œì„œ', 'ì´ë ¥ì„œ',
        'ì½”ë”©', 'íŒŒì´ì¬', 'ìˆ˜í•™', 'ì˜ì–´', 'ë²ˆì—­', 'ê³¼ì œ', 'ë ˆí¬íŠ¸',
        'ë„ˆëˆ„êµ¬', 'ì‚¬ëŒì´ì•¼', 'AIì•¼', 'ë­ì•¼ë„ˆ', 'ì •ì²´ê°€ë­'
    ],
    # ğŸš« ìš•ì„¤/ë¹„ì†ì–´ ì°¨ë‹¨
    'BLOCKED': [
        'ì‹œë°œ', 'ì”¨ë°œ', 'ã……ã…‚', 'ã…†ã…‚', 'ë³‘ì‹ ', 'ã…‚ã……', 'ì§€ë„', 'ã…ˆã„¹',
        'ê°œìƒˆë¼', 'ã„±ã……ã„²', 'êº¼ì ¸', 'ë‹¥ì³', 'ì£½ì–´', 'ë’¤ì ¸', 'ë¯¸ì¹œ', 'ã…ã…Š',
        'ì”¹', 'ì¡´ë‚˜', 'ã…ˆã„´', 'ì• ë¯¸', 'ì• ë¹„', 'ì¢†', 'ê±¸ë ˆ', 'ì°½ë…€',
        'fuck', 'shit', 'bitch', 'ì…', 'ì—¿ë¨¹ì–´'
    ],
}

# === ì œë„ í‚¤ì›Œë“œ (ë¹„êµ/ì„¤ëª…ìš©) ===
PROGRAM_KEYWORDS = {
    'ë³µìˆ˜ì „ê³µ': ['ë³µìˆ˜ì „ê³µ', 'ë³µì „', 'ë³µìˆ˜'],
    'ë¶€ì „ê³µ': ['ë¶€ì „ê³µ', 'ë¶€ì „'],
    'ìœµí•©ì „ê³µ': ['ìœµí•©ì „ê³µ', 'ìœµí•©'],
    'ìœµí•©ë¶€ì „ê³µ': ['ìœµí•©ë¶€ì „ê³µ'],
    'ì—°ê³„ì „ê³µ': ['ì—°ê³„ì „ê³µ', 'ì—°ê³„'],
    'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬': ['ë§ˆì´í¬ë¡œë””ê·¸ë¦¬', 'ë§ˆì´í¬ë¡œ', 'md', 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •', 'ì†Œë‹¨ìœ„ì „ê³µ', 'ì†Œë‹¨ìœ„', 'ë§ˆë””'],
}


# === Semantic Router ì´ˆê¸°í™” (ìºì‹±) ===
@st.cache_resource
def initialize_semantic_router():
    """Semantic Router ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)"""
    if not SEMANTIC_ROUTER_AVAILABLE or not SEMANTIC_ROUTER_ENABLED:
        return None
    
    # í•„ìˆ˜ í´ë˜ìŠ¤ê°€ import ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if Route is None or SemanticRouter is None or HuggingFaceEncoder is None:
        return None
    
    try:
        # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ (ë¬´ë£Œ)
        encoder = HuggingFaceEncoder(name="jhgan/ko-sroberta-multitask")
        
        # Route ìƒì„±
        routes = []
        for intent_name, utterances in INTENT_UTTERANCES.items():
            route = Route(
                name=intent_name,
                utterances=utterances,
            )
            routes.append(route)
        
        # SemanticRouter ìƒì„± (0.1.x ë²„ì „) - LocalIndex ëª…ì‹œì  ì§€ì •
        if LocalIndex is not None:
            index = LocalIndex()
            router = SemanticRouter(encoder=encoder, routes=routes, index=index)
        else:
            router = SemanticRouter(encoder=encoder, routes=routes)
        
        return router
    
    except Exception as e:
        st.warning(f"âš ï¸ Semantic Router ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\ní‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
        return None


# Semantic Router ì¸ìŠ¤í„´ìŠ¤
SEMANTIC_ROUTER = initialize_semantic_router()


# === AI ì˜ë„ ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸ ===
INTENT_CLASSIFICATION_PROMPT = """ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ë¥˜ AIì…ë‹ˆë‹¤. ì•„ë˜ ì˜ë„ ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.

[ì˜ë„ ëª©ë¡]
1. QUALIFICATION - ì‹ ì²­ ìê²©, ì§€ì› ìê²©, ëˆ„ê°€ ì‹ ì²­ ê°€ëŠ¥í•œì§€
2. APPLICATION_PERIOD - ì‹ ì²­ ê¸°ê°„, ì–¸ì œ ì‹ ì²­, ë§ˆê°ì¼
3. APPLICATION_METHOD - ì‹ ì²­ ë°©ë²•, ì ˆì°¨, ì–´ë–»ê²Œ ì‹ ì²­
4. CANCEL - í¬ê¸°, ì·¨ì†Œ, ì² íšŒ
5. CHANGE - ë³€ê²½, ìˆ˜ì •, ì „í™˜
6. PROGRAM_COMPARISON - ì œë„ ë¹„êµ, ì°¨ì´ì  (ë³µìˆ˜ì „ê³µ vs ë¶€ì „ê³µ ë“±)
7. PROGRAM_INFO - íŠ¹ì • ì œë„ ì„¤ëª… (ë³µìˆ˜ì „ê³µì´ ë­ì•¼?)
8. CREDIT_INFO - í•™ì , ì´ìˆ˜ í•™ì , ì¡¸ì—… ìš”ê±´
9. COURSE_SEARCH - ê³¼ëª© ì¡°íšŒ, ì»¤ë¦¬í˜ëŸ¼, ìˆ˜ì—…
10. CONTACT_SEARCH - ì—°ë½ì²˜, ì „í™”ë²ˆí˜¸, ì‚¬ë¬´ì‹¤
11. RECOMMENDATION - ì¶”ì²œ, ì–´ë–¤ ê²Œ ì¢‹ì„ê¹Œ, ì„ íƒ ê³ ë¯¼
12. GREETING - ì¸ì‚¬ (ì•ˆë…•, í•˜ì´)
13. OUT_OF_SCOPE - ë‹¤ì „ê³µ/ìœ ì—°í•™ì‚¬ì œë„ì™€ ì „í˜€ ë¬´ê´€í•œ ì§ˆë¬¸ (ë‚ ì”¨, ë§›ì§‘, ì·¨ì—…, íœ´í•™, ì¥í•™ê¸ˆ, ìˆ˜ê°•ì‹ ì²­, ê¸°ìˆ™ì‚¬ ë“±)

[ê·œì¹™]
- ë°˜ë“œì‹œ ì˜ë„ ì´ë¦„ë§Œ ì¶œë ¥ (ì˜ˆ: QUALIFICATION)
- ì—¬ëŸ¬ ì˜ë„ê°€ ì„ì—¬ ìˆìœ¼ë©´ ê°€ì¥ í•µì‹¬ì ì¸ ê²ƒ ì„ íƒ
- ë‹¤ì „ê³µ/ë³µìˆ˜ì „ê³µ/ë¶€ì „ê³µ/ìœµí•©ì „ê³µ/ë§ˆì´í¬ë¡œë””ê·¸ë¦¬/ì—°ê³„ì „ê³µê³¼ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸ì€ OUT_OF_SCOPE
"""


# ============================================================
# ğŸ”¥ ì˜ë„ ë¶„ë¥˜ í•¨ìˆ˜ (Semantic Router ì ìš©!)
# ============================================================

def extract_programs(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì œë„ëª… ì¶”ì¶œ"""
    found = []
    text_lower = text.lower()
    for program, keywords in PROGRAM_KEYWORDS.items():
        for kw in keywords:
            if kw in text_lower:
                if program not in found:
                    found.append(program)
                break
    return found


def extract_additional_info(user_input, intent):
    """ì¶”ê°€ ì •ë³´ ì¶”ì¶œ"""
    info = {}
    user_clean = user_input.lower().replace(' ', '')
    
    # ì œë„ëª… ì¶”ì¶œ
    found_programs = extract_programs(user_clean)
    if found_programs:
        info['programs'] = found_programs
        info['program'] = found_programs[0]
    
    # í•™ë²ˆ ì¶”ì¶œ
    year_match = re.search(r'(20\d{2})', user_input)
    if year_match:
        info['year'] = int(year_match.group(1))
    
    # í•™ì  ì¶”ì¶œ
    credit_match = re.search(r'(\d+)\s*í•™ì ', user_input)
    if credit_match:
        info['credits'] = int(credit_match.group(1))
    
    # ì „ê³µëª… ì¶”ì¶œ (COURSE_SEARCH, CONTACT_SEARCH ë“±ì— í•„ìš”)
    major_patterns = [
        r'([ê°€-í£A-Za-z]+(?:ìœµí•©)?ì „ê³µ)',  # ~ì „ê³µ
        r'([ê°€-í£A-Za-z]+í•™ê³¼)',  # ~í•™ê³¼
    ]
    
    for pattern in major_patterns:
        major_match = re.search(pattern, user_input)
        if major_match:
            major_name = major_match.group(1)
            # ì œë„ëª…ì€ ì œì™¸ (ë³µìˆ˜ì „ê³µ, ë¶€ì „ê³µ ë“±)
            if major_name not in ['ë³µìˆ˜ì „ê³µ', 'ë¶€ì „ê³µ', 'ìœµí•©ì „ê³µ', 'ìœµí•©ë¶€ì „ê³µ', 'ì—°ê³„ì „ê³µ', 'ë‹¤ì „ê³µ']:
                info['major'] = major_name
                break
    
    return info


def classify_with_semantic_router(user_input):
    """Semantic Routerë¥¼ ì‚¬ìš©í•œ ì˜ë„ ë¶„ë¥˜"""
    if SEMANTIC_ROUTER is None:
        return None, 0.0
    
    try:
        result = SEMANTIC_ROUTER(user_input)
        if result and result.name:
            # scoreëŠ” resultì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©
            return result.name, 0.8
        return None, 0.0
    except Exception as e:
        return None, 0.0


def classify_with_keywords(user_input):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ (í´ë°±)"""
    user_clean = user_input.lower().replace(' ', '')
    
    priority_order = [
        'QUALIFICATION',
        'APPLICATION_PERIOD', 
        'APPLICATION_METHOD',
        'CANCEL',
        'CHANGE',
        'PROGRAM_COMPARISON',
        'RECOMMENDATION',
        'CREDIT_INFO',
        'PROGRAM_INFO',
        'COURSE_SEARCH',
        'CONTACT_SEARCH',
        'GREETING',
    ]
    
    for intent in priority_order:
        keywords = INTENT_KEYWORDS.get(intent, [])
        if any(kw in user_clean for kw in keywords):
            return intent
    
    return None


def classify_with_ai(user_input):
    """AIë¥¼ ì‚¬ìš©í•œ ì˜ë„ ë¶„ë¥˜"""
    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=f"ì§ˆë¬¸: {user_input}\n\nì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.",
            config={
                'system_instruction': INTENT_CLASSIFICATION_PROMPT,
                'temperature': 0,
                'max_output_tokens': 50
            }
        )
        
        intent = response.text.strip().upper()
        
        valid_intents = [
            'QUALIFICATION', 'APPLICATION_PERIOD', 'APPLICATION_METHOD',
            'CANCEL', 'CHANGE', 'PROGRAM_COMPARISON', 'PROGRAM_INFO',
            'CREDIT_INFO', 'COURSE_SEARCH', 'CONTACT_SEARCH',
            'RECOMMENDATION', 'GREETING', 'OUT_OF_SCOPE'
        ]
        
        for valid in valid_intents:
            if valid in intent:
                return valid
        
        # ë‹¤ì „ê³µê³¼ ë¬´ê´€í•œ ì§ˆë¬¸ì€ OUT_OF_SCOPE
        return 'OUT_OF_SCOPE'
    except:
        return 'OUT_OF_SCOPE'


def classify_intent(user_input, use_ai_fallback=True):
    """
    ğŸ”¥ Level 2 ì˜ë„ ë¶„ë¥˜ (Semantic Router ì ìš©!)
    
    ğŸš« ìµœìš°ì„ : ìš•ì„¤/ë¹„ì†ì–´ ì°¨ë‹¨ â† ğŸ†• ì¶”ê°€!
    0ë‹¨ê³„: ë³µí•© ì¡°ê±´ ê²€ì‚¬ (êµ¬ì²´ì ì¸ ì§ˆë¬¸ ìš°ì„ )
    1ë‹¨ê³„: Semantic Router (ì˜ë¯¸ ê¸°ë°˜) â† ğŸ†• í•µì‹¬!
    2ë‹¨ê³„: í‚¤ì›Œë“œ ë§¤ì¹­ (í´ë°±)
    3ë‹¨ê³„: AI ë¶„ë¥˜ (ìµœì¢… í´ë°±)
    
    Returns: (intent, method, extracted_info)
    """
    user_clean = user_input.lower().replace(' ', '')
    
    # ============================================================
    # ğŸš« ìµœìš°ì„ : ìš•ì„¤/ë¹„ì†ì–´ ì°¨ë‹¨ (ê°€ì¥ ë¨¼ì € ê²€ì‚¬!)
    # ============================================================
    blocked_keywords = INTENT_KEYWORDS.get('BLOCKED', [])
    if any(kw in user_clean for kw in blocked_keywords):
        return 'BLOCKED', 'blocked', {}
    
    # ê´„í˜¸ í‘œí˜„ ì •ê·œí™”
    bracket_pattern = r'([ê°€-í£a-z]+)\(([ê°€-í£a-z]+)\)'
    bracket_match = re.search(bracket_pattern, user_clean)
    if bracket_match:
        inner_term = bracket_match.group(2)
        if inner_term in ['ë§ˆì´í¬ë¡œë””ê·¸ë¦¬', 'ë§ˆì´í¬ë¡œ', 'md', 'ì†Œë‹¨ìœ„']:
            user_clean = user_clean.replace(bracket_match.group(0), 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬')
    
    # ============================================================
    # ğŸ”¥ 0ë‹¨ê³„: ë³µí•© ì¡°ê±´ (ìš°ì„  ì²˜ë¦¬!)
    # ============================================================
    has_year = bool(re.search(r'(20\d{2}|í•™ë²ˆ|\d{2}í•™ë²ˆ)', user_clean))
    has_credit_detail = any(kw in user_clean for kw in ['ì „í•„', 'ì „ì„ ', 'ì´ìˆ˜í•œ', 'ë“¤ì€', 'ìˆ˜ê°•í•œ'])
    has_recommend = any(kw in user_clean for kw in ['ì¶”ì²œ', 'ë­í• ê¹Œ', 'ì–´ë–¤ê²Œì¢‹', 'ê³¨ë¼', 'ë­ê°€ì¢‹', 'ì–´ë–¤ê±¸', 'ë­í•´ì•¼', 'ì¢‹ì„ê¹Œ'])
    has_credit_general = any(kw in user_clean for kw in ['í•™ì ', 'ëª‡í•™ì '])
    has_major = bool(re.search(r'([ê°€-í£]+(?:í•™|ê³µí•™|ê³¼í•™|ì „ê³µ))', user_clean))
    
    # ğŸ†• êµê³¼ëª©/ê³¼ëª© ê²€ìƒ‰ ìš°ì„  ì²˜ë¦¬ (íŠ¹ì • ì „ê³µëª… + ê³¼ëª©/êµê³¼ëª© í‚¤ì›Œë“œ)
    has_course_keyword = any(kw in user_clean for kw in ['êµê³¼ëª©', 'ê³¼ëª©', 'ì–´ë–¤ê³¼ëª©', 'ë¬´ìŠ¨ê³¼ëª©', 'ì»¤ë¦¬í˜ëŸ¼', 'ìˆ˜ì—…'])
    if has_course_keyword and has_major:
        return 'COURSE_SEARCH', 'complex', extract_additional_info(user_input, 'COURSE_SEARCH')
    
    # ë§ì¶¤í˜• ì¶”ì²œ ìš”ì²­
    if has_recommend:
        if has_year and (has_credit_detail or has_credit_general):
            return 'RECOMMENDATION', 'complex', extract_additional_info(user_input, 'RECOMMENDATION')
        if has_major and (has_credit_detail or has_credit_general):
            return 'RECOMMENDATION', 'complex', extract_additional_info(user_input, 'RECOMMENDATION')
        if has_credit_detail:
            return 'RECOMMENDATION', 'complex', extract_additional_info(user_input, 'RECOMMENDATION')
    
    # íŠ¹ì • ì œë„ + íŠ¹ì • ì§ˆë¬¸
    found_programs = extract_programs(user_clean)
    
    if found_programs:
        program = found_programs[0]
        
        if any(kw in user_clean for kw in ['ìê²©', 'ì‹ ì²­í• ìˆ˜ìˆ', 'ê°€ëŠ¥í•œì§€', 'ì¡°ê±´']):
            return 'QUALIFICATION', 'complex', {'program': program, 'programs': found_programs}
        
        if any(kw in user_clean for kw in ['ì–¸ì œ', 'ê¸°ê°„', 'ë§ˆê°']):
            return 'APPLICATION_PERIOD', 'complex', {'program': program, 'programs': found_programs}
        
        if any(kw in user_clean for kw in ['ì–´ë–»ê²Œ', 'ë°©ë²•', 'ì ˆì°¨']):
            return 'APPLICATION_METHOD', 'complex', {'program': program, 'programs': found_programs}
        
        if has_credit_general and not has_recommend:
            return 'CREDIT_INFO', 'complex', {'program': program, 'programs': found_programs}
    
    # ì œë„ ë¹„êµ íŠ¹ìˆ˜ ì²˜ë¦¬
    if any(kw in user_clean for kw in INTENT_KEYWORDS.get('PROGRAM_COMPARISON', [])):
        if len(found_programs) >= 2:
            return 'PROGRAM_COMPARISON', 'keyword', {'programs': found_programs}
    
    if 'ì™€' in user_clean or 'ê³¼' in user_clean or 'ì´ë‘' in user_clean:
        if 'ê³¼ì •' not in user_clean:
            if len(found_programs) >= 2:
                return 'PROGRAM_COMPARISON', 'keyword', {'programs': found_programs}
    
    # ============================================================
    # ğŸ”¥ 1ë‹¨ê³„: Semantic Router (ì˜ë¯¸ ê¸°ë°˜ ë¶„ë¥˜) â† í•µì‹¬!
    # ============================================================
    if SEMANTIC_ROUTER is not None:
        semantic_intent, score = classify_with_semantic_router(user_input)
        if semantic_intent:
            extracted_info = extract_additional_info(user_input, semantic_intent)
            return semantic_intent, 'semantic', extracted_info
    
    # ============================================================
    # ğŸ”¹ 2ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ (í´ë°±)
    # ============================================================
    keyword_intent = classify_with_keywords(user_input)
    if keyword_intent:
        extracted_info = extract_additional_info(user_input, keyword_intent)
        return keyword_intent, 'keyword', extracted_info
    
    # ì œë„ ì„¤ëª… ì§ˆë¬¸
    if found_programs:
        explanation_keywords = ['ì€?', 'ëŠ”?', 'ì´?', 'ê°€?', 'ë­', 'ë¬´ì—‡', 'ì•Œë ¤', 'ì„¤ëª…']
        if any(kw in user_clean for kw in explanation_keywords):
            return 'PROGRAM_INFO', 'keyword', {'program': found_programs[0]}
    
    # ============================================================
    # ğŸ”¹ 3ë‹¨ê³„: AI ë¶„ë¥˜ (ìµœì¢… í´ë°±)
    # ============================================================
    if use_ai_fallback:
        try:
            ai_intent = classify_with_ai(user_input)
            if ai_intent != 'GENERAL':
                extracted_info = extract_additional_info(user_input, ai_intent)
                return ai_intent, 'ai', extracted_info
        except:
            pass
    
    # ============================================================
    # ğŸš« ìµœì¢…: ë‹¤ì „ê³µê³¼ ë¬´ê´€í•œ ì§ˆë¬¸ â†’ "ëª¨ë¦…ë‹ˆë‹¤" ì‘ë‹µ
    # ============================================================
    return 'OUT_OF_SCOPE', 'fallback', {}


# ============================================================
# ğŸ¯ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë“¤ (ì˜ë„ë³„ ë‹µë³€ ìƒì„±) - v2 ìŠ¤íƒ€ì¼ (FAQ í™œìš©)
# ============================================================

def handle_qualification(user_input, extracted_info, data_dict):
    """ì‹ ì²­ ìê²© ì§ˆë¬¸ ì²˜ë¦¬"""
    programs = data_dict.get('programs', PROGRAM_INFO)
    
    response = "## ğŸ“‹ ë‹¤ì „ê³µ ì œë„ë³„ ì‹ ì²­ ìê²© ìš”ê±´\n\n"
    response += "| ì œë„ | ì‹ ì²­ ìê²© |\n"
    response += "|------|----------|\n"
    
    for p_name, p_info in programs.items():
        qual = p_info.get('qualification', '-')
        response += f"| **{p_name}** | {qual} |\n"
    
    response += "\n---\n"
    response += "ğŸ’¡ **ì°¸ê³ **: ì‹ ì²­ ìê²©ì€ í•™ì¹™ ê°œì •ì— ë”°ë¼ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
    response += CONTACT_MESSAGE
    
    return response, "QUALIFICATION"


def handle_application_period(user_input, extracted_info, data_dict):
    """ì‹ ì²­ ê¸°ê°„ ì§ˆë¬¸ ì²˜ë¦¬"""
    faq_data = data_dict.get('faq', FAQ_DATA)
    
    # FAQì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
    period_answer = None
    for faq in faq_data:
        q = faq.get('ì§ˆë¬¸', '').lower().replace(' ', '')
        if 'ì‹ ì²­' in q and ('ê¸°ê°„' in q or 'ì–¸ì œ' in q):
            period_answer = faq.get('ë‹µë³€', '')
            break
    
    response = f"## {APP_PERIOD_TITLE}\n\n"
    response += f"{APP_PERIOD_INTRO}\n\n"
    response += "### ğŸ“Œ ì‹ ì²­ ì‹œê¸°\n\n"
    response += "| ì´ìˆ˜ í¬ë§ í•™ê¸° | ì‹ ì²­ ì‹œê¸° |\n"
    response += "|--------------|----------|\n"
    response += f"| **1í•™ê¸°** ì´ìˆ˜ í¬ë§ | {APP_PERIOD_1ST} |\n"
    response += f"| **2í•™ê¸°** ì´ìˆ˜ í¬ë§ | {APP_PERIOD_2ND} |\n\n"
    
    response += "### â° ì‹ ì²­ ê°€ëŠ¥ ì‹œì \n"
    response += f"- {APP_PERIOD.get('start_info', '**ì…í•™ í›„ ì²« í•™ê¸°ë¶€í„°** ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤.')}\n"
    response += f"- {APP_PERIOD.get('restriction', 'ì¡¸ì—… ì˜ˆì • í•™ê¸°ì—ëŠ” ì‹ ì²­ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')}\n\n"
    
    if period_answer:
        response += f"### ğŸ“‹ ì°¸ê³  ì •ë³´\n{period_answer}\n\n"
    
    response += "---\n"
    response += f"âš ï¸ ì •í™•í•œ ì¼ì •ì€ í•™êµ í™ˆí˜ì´ì§€ **[í•™ì‚¬ê³µì§€]({ACADEMIC_NOTICE_URL})**ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n\n"
    response += CONTACT_MESSAGE
    
    return response, "APPLICATION_PERIOD"


def handle_application_method(user_input, extracted_info, data_dict):
    """ì‹ ì²­ ë°©ë²•/ì ˆì°¨ ì§ˆë¬¸ ì²˜ë¦¬"""
    faq_data = data_dict.get('faq', FAQ_DATA)
    
    # FAQì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
    method_answers = []
    for faq in faq_data:
        q = faq.get('ì§ˆë¬¸', '').lower().replace(' ', '')
        if ('ì‹ ì²­' in q or 'ì§€ì›' in q) and ('ë°©ë²•' in q or 'ì ˆì°¨' in q or 'ì–´ë–»ê²Œ' in q):
            method_answers.append({
                'question': faq.get('ì§ˆë¬¸', ''),
                'answer': faq.get('ë‹µë³€', '')
            })
    
    response = "## ğŸ“ ë‹¤ì „ê³µ ì‹ ì²­ ë°©ë²• ì•ˆë‚´\n\n"
    
    if method_answers:
        for item in method_answers[:3]:
            response += f"**Q. {item['question']}**\n\n"
            response += f"A. {item['answer']}\n\n"
            response += "---\n\n"
    else:
        response += "**ì¼ë°˜ì ì¸ ì‹ ì²­ ì ˆì°¨:**\n\n"
        response += "1ï¸âƒ£ **ì‹ ì²­ ì‹œê¸° í™•ì¸**: í•™ì‚¬ ê³µì§€ì‚¬í•­ì—ì„œ ì‹ ì²­ ê¸°ê°„ í™•ì¸\n\n"
        response += "2ï¸âƒ£ **ìê²© ìš”ê±´ í™•ì¸**: ë³¸ì¸ì˜ í•™ë…„, í‰ì  ë“± ìê²© ì¶©ì¡± ì—¬ë¶€ í™•ì¸\n\n"
        response += "3ï¸âƒ£ **ì˜¨ë¼ì¸ ì‹ ì²­**: í•™ì‚¬ê³µì§€ì— ì•ˆë‚´ëœ ë°©ë²•ìœ¼ë¡œ ì‹ ì²­ì„œ ì‘ì„±\n\n"
        response += "4ï¸âƒ£ **ìŠ¹ì¸ ëŒ€ê¸°**: í•´ë‹¹ í•™ê³¼ì—ì„œ ìŠ¹ì¸ ì ˆì°¨ ì§„í–‰\n\n"
        response += "---\n\n"
    
    response += "âš ï¸ ìì„¸í•œ ë‚´ìš©ì€ í•™êµ í™ˆí˜ì´ì§€ **[í•™ì‚¬ê³µì§€](https://www.hknu.ac.kr/kor/562/subview.do)**ë¥¼ ì°¸ê³ í•˜ê±°ë‚˜\n\n"
    response += CONTACT_MESSAGE
    
    return response, "APPLICATION_METHOD"


def handle_cancel(user_input, extracted_info, data_dict):
    """í¬ê¸°/ì·¨ì†Œ ì§ˆë¬¸ ì²˜ë¦¬"""
    faq_data = data_dict.get('faq', FAQ_DATA)
    
    # FAQì—ì„œ í¬ê¸°/ì·¨ì†Œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
    cancel_answers = []
    for faq in faq_data:
        q = faq.get('ì§ˆë¬¸', '').lower()
        if 'í¬ê¸°' in q or 'ì·¨ì†Œ' in q or 'ì² íšŒ' in q:
            cancel_answers.append({
                'question': faq.get('ì§ˆë¬¸', ''),
                'answer': faq.get('ë‹µë³€', '')
            })
    
    response = "## âŒ ë‹¤ì „ê³µ í¬ê¸°/ì·¨ì†Œ ì•ˆë‚´\n\n"
    
    if cancel_answers:
        for item in cancel_answers[:3]:
            response += f"**Q. {item['question']}**\n\n"
            response += f"A. {item['answer']}\n\n"
            response += "---\n\n"
    else:
        response += "**ë‹¤ì „ê³µ í¬ê¸° ì•ˆë‚´:**\n\n"
        response += "- **í¬ê¸° ì‹œê¸°**: ë§¤ í•™ê¸° ìˆ˜ê°•ì‹ ì²­ ê¸°ê°„ ì¤‘ ê°€ëŠ¥\n"
        response += "- **í¬ê¸° ë°©ë²•**: í•™ì‚¬ê³µì§€ í™•ì¸ í›„ ì‹ ì²­\n"
        response += "- **ìœ ì˜ì‚¬í•­**: ì´ìˆ˜í•œ í•™ì ì€ ììœ ì„ íƒ í•™ì ìœ¼ë¡œ ì¸ì •\n\n"
        response += "---\n\n"
    
    response += "âš ï¸ ìì„¸í•œ ë‚´ìš©ì€ í•™êµ í™ˆí˜ì´ì§€ **[í•™ì‚¬ê³µì§€](https://www.hknu.ac.kr/kor/562/subview.do)**ë¥¼ ì°¸ê³ í•˜ê±°ë‚˜\n\n"
    response += CONTACT_MESSAGE
    
    return response, "CANCEL"


def handle_change(user_input, extracted_info, data_dict):
    """ë³€ê²½ ì§ˆë¬¸ ì²˜ë¦¬"""
    faq_data = data_dict.get('faq', FAQ_DATA)
    
    # FAQì—ì„œ ë³€ê²½ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
    change_answers = []
    for faq in faq_data:
        q = faq.get('ì§ˆë¬¸', '').lower()
        if 'ë³€ê²½' in q or 'ìˆ˜ì •' in q or 'ë°”ê¾¸' in q or 'ì „í™˜' in q:
            change_answers.append({
                'question': faq.get('ì§ˆë¬¸', ''),
                'answer': faq.get('ë‹µë³€', '')
            })
    
    response = "## ğŸ”„ ë‹¤ì „ê³µ ë³€ê²½ ì•ˆë‚´\n\n"
    
    if change_answers:
        for item in change_answers[:3]:
            response += f"**Q. {item['question']}**\n\n"
            response += f"A. {item['answer']}\n\n"
            response += "---\n\n"
    else:
        response += "**ë‹¤ì „ê³µ ë³€ê²½ ì•ˆë‚´:**\n\n"
        response += "- ë‹¤ì „ê³µ **ì¢…ë¥˜ ë³€ê²½** (ì˜ˆ: ë³µìˆ˜ì „ê³µ â†’ ë¶€ì „ê³µ): ê¸°ì¡´ í¬ê¸° í›„ ì¬ì‹ ì²­\n"
        response += "- ë‹¤ì „ê³µ **ì „ê³µ ë³€ê²½** (ì˜ˆ: Aì „ê³µ â†’ Bì „ê³µ): ê¸°ì¡´ í¬ê¸° í›„ ì¬ì‹ ì²­\n\n"
        response += "â€» ë™ì¼ í•™ê¸°ì— í¬ê¸°ì™€ ì‹ ì²­ì„ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
        response += "---\n\n"
    
    response += "âš ï¸ ìì„¸í•œ ë‚´ìš©ì€ í•™êµ í™ˆí˜ì´ì§€ **[í•™ì‚¬ê³µì§€](https://www.hknu.ac.kr/kor/562/subview.do)**ë¥¼ ì°¸ê³ í•˜ê±°ë‚˜\n\n"
    response += CONTACT_MESSAGE
    
    return response, "CHANGE"


def handle_program_comparison(user_input, extracted_info, data_dict):
    """ì œë„ ë¹„êµ ì§ˆë¬¸ ì²˜ë¦¬"""
    programs_to_compare = extracted_info.get('programs', [])
    programs = data_dict.get('programs', PROGRAM_INFO)
    
    if len(programs_to_compare) < 2:
        programs_to_compare = list(programs.keys())[:4]
    
    comparison_data = []
    for program_name in programs_to_compare:
        if program_name in programs:
            comparison_data.append({
                'name': program_name,
                **programs[program_name]
            })
        elif program_name == 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬' and 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •' in programs:
            comparison_data.append({
                'name': 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)',
                **programs['ì†Œë‹¨ìœ„ì „ê³µê³¼ì •']
            })
    
    if len(comparison_data) < 2:
        response = "## ğŸ“Š ë‹¤ì „ê³µ ì œë„ ë¹„êµ\n\n"
        response += "| êµ¬ë¶„ | ë³µìˆ˜ì „ê³µ | ë¶€ì „ê³µ | ìœµí•©ì „ê³µ | ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ |\n"
        response += "|------|----------|--------|----------|----------------|\n"
        response += "| **ì´ìˆ˜í•™ì ** | 36í•™ì  ì´ìƒ | 21í•™ì  ì´ìƒ | 36í•™ì  ì´ìƒ | 12í•™ì  |\n"
        response += "| **í•™ìœ„í‘œê¸°** | 2ê°œ í•™ìœ„ | ë¶€ì „ê³µ í‘œê¸° | ìœµí•©ì „ê³µëª… | ì´ìˆ˜ì¦ |\n"
        response += "| **ë³¸ì „ê³µ ê°ì¶•** | ìˆìŒ | ìˆìŒ | ìˆìŒ | ì—†ìŒ |\n"
        response += "| **ë‚œì´ë„** | â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­ |\n\n"
        response += CONTACT_MESSAGE
        return response, "PROGRAM_COMPARISON"
    
    response = f"## ğŸ“Š {' vs '.join([d['name'] for d in comparison_data])} ë¹„êµ\n\n"
    response += "| êµ¬ë¶„ | " + " | ".join([d['name'] for d in comparison_data]) + " |\n"
    response += "|------" + "|------" * len(comparison_data) + "|\n"
    
    response += "| **ì´ìˆ˜í•™ì ** | " + " | ".join([d.get('credits_multi', '-') for d in comparison_data]) + " |\n"
    response += "| **ë³¸ì „ê³µ** | " + " | ".join([d.get('credits_primary', '-') for d in comparison_data]) + " |\n"
    
    quals = []
    for d in comparison_data:
        q = d.get('qualification', '-')
        quals.append(q[:15] + '...' if len(q) > 15 else q)
    response += "| **ì‹ ì²­ìê²©** | " + " | ".join(quals) + " |\n"
    
    response += "| **í•™ìœ„í‘œê¸°** | " + " | ".join([str(d.get('degree', '-')) for d in comparison_data]) + " |\n"
    response += "| **ë‚œì´ë„** | " + " | ".join([str(d.get('difficulty', '-')) for d in comparison_data]) + " |\n"
    
    response += "\n---\n"
    response += CONTACT_MESSAGE
    
    return response, "PROGRAM_COMPARISON"


def handle_credit_info(user_input, extracted_info, data_dict):
    """í•™ì  ì •ë³´ ì§ˆë¬¸ ì²˜ë¦¬"""
    primary_req = data_dict.get('primary_req', PRIMARY_REQ)
    grad_req = data_dict.get('grad_req', GRADUATION_REQ)
    
    response = "## ğŸ“– ë‹¤ì „ê³µ ì œë„ë³„ ì´ìˆ˜ í•™ì \n\n"
    response += "âš ï¸ **ì „ê³µí•„ìˆ˜/ì „ê³µì„ íƒ í•™ì ì€ ë³¸ì „ê³µê³¼ í•™ë²ˆì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**\n\n"
    
    # ì œë„ ìœ í˜• ëª©ë¡
    program_types = ["ë³µìˆ˜ì „ê³µ", "ë¶€ì „ê³µ", "ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ", "ì—°ê³„ì „ê³µ"]
    
    # 2025í•™ë²ˆ ê²½ì˜í•™ì „ê³µ ì˜ˆì‹œ
    response += "### ğŸ“Œ ì˜ˆì‹œ: 2025í•™ë²ˆ ê²½ì˜í•™ì „ê³µ ê¸°ì¤€\n\n"
    
    response += "#### ğŸ“š ë³¸ì „ê³µ ì´ìˆ˜ í•™ì  (ë‹¤ì „ê³µ ì‹ ì²­ ì‹œ ë³€ê²½)\n\n"
    response += "| ì œë„ | ì „ê³µí•„ìˆ˜ | ì „ê³µì„ íƒ | ê³„ |\n"
    response += "|------|----------|----------|----|\n"
    
    if not primary_req.empty:
        for p_type in program_types:
            # ê²½ì˜í•™ì „ê³µ + 2025í•™ë²ˆ ê¸°ì¤€ í•„í„°ë§
            filtered = primary_req[
                (primary_req['ì œë„ìœ í˜•'].str.contains(p_type, na=False)) &
                (primary_req['ì „ê³µëª…'].str.contains('ê²½ì˜í•™', na=False)) &
                (primary_req['ê¸°ì¤€í•™ë²ˆ'] == 2025)
            ]
            if filtered.empty:
                # 2025í•™ë²ˆì´ ì—†ìœ¼ë©´ ê°€ì¥ ìµœê·¼ í•™ë²ˆ
                filtered = primary_req[
                    (primary_req['ì œë„ìœ í˜•'].str.contains(p_type, na=False)) &
                    (primary_req['ì „ê³µëª…'].str.contains('ê²½ì˜í•™', na=False))
                ]
            if not filtered.empty:
                row = filtered.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False).iloc[0]
                req = row.get('ë³¸ì „ê³µ_ì „ê³µí•„ìˆ˜', '-')
                elec = row.get('ë³¸ì „ê³µ_ì „ê³µì„ íƒ', '-')
                total = row.get('ë³¸ì „ê³µ_ê³„', '-')
                response += f"| **{p_type}** | {req} | {elec} | {total} |\n"
    else:
        response += "| - | ë°ì´í„° ì—†ìŒ | - | - |\n"
    
    response += "\n#### ğŸ“ ë‹¤ì „ê³µ ì´ìˆ˜ í•™ì \n\n"
    response += "| ì œë„ | ì „ê³µí•„ìˆ˜ | ì „ê³µì„ íƒ | ê³„ |\n"
    response += "|------|----------|----------|----|\n"
    
    if not grad_req.empty:
        for p_type in program_types:
            filtered = grad_req[grad_req['ì œë„ìœ í˜•'].str.contains(p_type, na=False)]
            if not filtered.empty:
                row = filtered.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False).iloc[0]
                req = row.get('ë‹¤ì „ê³µ_ì „ê³µí•„ìˆ˜', '-')
                elec = row.get('ë‹¤ì „ê³µ_ì „ê³µì„ íƒ', '-')
                total = row.get('ë‹¤ì „ê³µ_ê³„', '-')
                response += f"| **{p_type}** | {req} | {elec} | {total} |\n"
    else:
        response += "| - | ë°ì´í„° ì—†ìŒ | - | - |\n"
    
    response += "\n---\n"
    response += "ğŸ’¡ **ì°¸ê³ **: ë‹¤ì „ê³µ ì‹ ì²­ ì‹œ ë³¸ì „ê³µ ì´ìˆ˜ í•™ì ì´ ì¤„ì–´ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ì¸ì˜ ì „ê³µê³¼ í•™ë²ˆì— ë§ëŠ” ì •í™•í•œ í•™ì ì€ ì™¼ìª½ ë©”ë‰´ì˜ 'ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´'ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\n\n"
    response += "âš ï¸ ê¸°íƒ€ ë‚´ìš©ì€ í•™êµ í™ˆí˜ì´ì§€ **[í•™ì‚¬ê³µì§€](https://www.hknu.ac.kr/kor/562/subview.do)**ë¥¼ ì°¸ê³ í•˜ê±°ë‚˜\n\n"
    response += CONTACT_MESSAGE
    
    return response, "CREDIT_INFO"


def handle_program_info(user_input, extracted_info, data_dict):
    """ì œë„ ì„¤ëª… ì§ˆë¬¸ ì²˜ë¦¬"""
    program_name = extracted_info.get('program', '')
    programs = data_dict.get('programs', PROGRAM_INFO)
    
    program_mapping = {
        'ë³µìˆ˜ì „ê³µ': 'ë³µìˆ˜ì „ê³µ',
        'ë¶€ì „ê³µ': 'ë¶€ì „ê³µ',
        'ìœµí•©ì „ê³µ': 'ìœµí•©ì „ê³µ',
        'ìœµí•©ë¶€ì „ê³µ': 'ìœµí•©ë¶€ì „ê³µ',
        'ì—°ê³„ì „ê³µ': 'ì—°ê³„ì „ê³µ',
        'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬': 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •',
    }
    
    actual_name = program_mapping.get(program_name, program_name)
    
    if actual_name not in programs:
        for key in programs.keys():
            if program_name in key or key in program_name:
                actual_name = key
                break
    
    if actual_name not in programs:
        return f"'{program_name}' ì œë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nğŸ“ ë¬¸ì˜: ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ERROR"
    
    info = programs[actual_name]
    display_name = actual_name
    if actual_name == 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •':
        display_name = 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)'
    
    features_text = '\n'.join([f"- {f.strip()}" for f in info.get('features', [])]) if info.get('features') else 'ì—†ìŒ'
    
    response = f"## ğŸ“ {display_name}\n\n"
    response += f"### ğŸ“– ê°œìš”\n{info.get('description', '-')}\n\n"
    
    response += "### ğŸ“š ì´ìˆ˜í•™ì \n"
    response += "| êµ¬ë¶„ | í•™ì  |\n"
    response += "|------|------|\n"
    response += f"| êµì–‘ | {info.get('credits_general', '-')} |\n"
    response += f"| ì›ì „ê³µ(ë³¸ì „ê³µ) | {info.get('credits_primary', '-')} |\n"
    response += f"| ë‹¤ì „ê³µ | {info.get('credits_multi', '-')} |\n\n"
    
    response += f"### âœ… ì‹ ì²­ìê²©\n{info.get('qualification', '-')}\n\n"
    response += f"### ğŸ“œ í•™ìœ„í‘œê¸°\n{info.get('degree', '-')}\n\n"
    response += f"### â­ ë‚œì´ë„\n{info.get('difficulty', '-')}\n\n"
    response += f"### âœ¨ íŠ¹ì§•\n{features_text}\n\n"
    
    if info.get('notes'):
        response += f"### ğŸ’¡ ìœ ì˜ì‚¬í•­\n{info['notes']}\n\n"
    
    response += "---\n"
    response += CONTACT_MESSAGE
    
    return response, "PROGRAM_INFO"


def handle_course_search(user_input, extracted_info, data_dict):
    """ê³¼ëª© ì¡°íšŒ ì§ˆë¬¸ ì²˜ë¦¬"""
    major = extracted_info.get('major')
    year = extracted_info.get('year')
    
    courses_data = data_dict.get('courses', COURSES_DATA)
    
    # ì „ê³µëª…ì´ ì—†ìœ¼ë©´ ì…ë ¥ì—ì„œ ì§ì ‘ ì°¾ê¸°
    if not major and not courses_data.empty:
        user_clean = user_input.replace(' ', '')
        for m in courses_data['ì „ê³µëª…'].unique():
            m_clean = str(m).replace(' ', '')
            if m_clean in user_clean or user_clean in m_clean:
                major = m
                break
            # ë¶€ë¶„ ë§¤ì¹­ë„ ì‹œë„ (ì˜ˆ: "AIë°˜ë„ì²´" -> "AIë°˜ë„ì²´ìœµí•©ì „ê³µ")
            if len(m_clean) > 3:
                keyword = m_clean.replace('ì „ê³µ', '').replace('ìœµí•©', '')[:4]
                if keyword in user_clean:
                    major = m
                    break
    
    if not major:
        return """## ğŸ“š ê³¼ëª© ì¡°íšŒ

ì–´ë–¤ ì „ê³µì˜ ê³¼ëª©ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?

ğŸ’¡ **ì˜ˆì‹œ ì§ˆë¬¸:**
- "AIë°˜ë„ì²´ìœµí•©ì „ê³µ ì–´ë–¤ ê³¼ëª© ë“¤ì–´?"
- "ë¹…ë°ì´í„°ìœµí•©ì „ê³µ êµê³¼ëª© ì•Œë ¤ì¤˜"
- "ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ì „ê³µ ê³¼ëª© ë³´ì—¬ì¤˜"

ğŸ“ ë¬¸ì˜: ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.""", "COURSE_SEARCH"
    
    if courses_data.empty:
        return f"'{major}' ê³¼ëª© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nğŸ“ ë¬¸ì˜: ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ERROR"
    
    # ì „ê³µëª…ìœ¼ë¡œ í•„í„°ë§ (ì •í™•í•œ ë§¤ì¹­ ìš°ì„ , ì—†ìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­)
    major_courses = courses_data[courses_data['ì „ê³µëª…'] == major]
    
    if major_courses.empty:
        # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
        major_keyword = major.replace('ì „ê³µ', '').replace('ìœµí•©', '')
        major_courses = courses_data[
            courses_data['ì „ê³µëª…'].str.contains(major_keyword, case=False, na=False)
        ]
    
    if major_courses.empty:
        return f"'{major}' ê³¼ëª© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nğŸ“ ë¬¸ì˜: ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ERROR"
    
    # ì œë„ìœ í˜• ì •ë³´ í‘œì‹œ
    program_types = major_courses['ì œë„ìœ í˜•'].unique().tolist()
    
    if year:
        major_courses = major_courses[
            (major_courses['í•™ë…„'] == year) |
            (major_courses['í•™ë…„'].astype(str) == str(year))
        ]
    
    if major_courses.empty:
        return f"'{major}' {year}í•™ë…„ ê³¼ëª© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\nğŸ“ ë¬¸ì˜: ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ERROR"
    
    # ì‹¤ì œ ì „ê³µëª… ê°€ì ¸ì˜¤ê¸°
    actual_major = major_courses['ì „ê³µëª…'].iloc[0]
    
    response = f"## ğŸ“š {actual_major} êµê³¼ëª© ì•ˆë‚´\n\n"
    response += f"ğŸ“‹ **ì œë„ìœ í˜•**: {', '.join([str(pt) for pt in program_types if pd.notna(pt)])}\n\n"
    
    years_in_data = sorted([int(y) for y in major_courses['í•™ë…„'].dropna().unique()])
    
    for y in years_in_data:
        year_data = major_courses[major_courses['í•™ë…„'] == y]
        response += f"### {y}í•™ë…„\n\n"
        
        for _, row in year_data.iterrows():
            sem = row.get('í•™ê¸°', '-')
            course_type = row.get('ì´ìˆ˜êµ¬ë¶„', '-')
            course_name = row.get('ê³¼ëª©ëª…', '-')
            credit = row.get('í•™ì ', '-')
            
            if 'í•„ìˆ˜' in str(course_type):
                badge = "ğŸ”´"
            elif 'ì„ íƒ' in str(course_type):
                badge = "ğŸŸ¢"
            else:
                badge = "ğŸ”µ"
            
            try:
                credit_str = f"{int(credit)}í•™ì "
            except:
                credit_str = f"{credit}í•™ì " if pd.notna(credit) else ""
            
            try:
                sem_str = f"{int(sem)}í•™ê¸°"
            except:
                sem_str = f"{sem}" if pd.notna(sem) else ""
            
            response += f"{badge} [{course_type}] {course_name} ({credit_str}) - {sem_str}\n"
        
        response += "\n"
    
    response += "---\n"
    response += CONTACT_MESSAGE
    
    return response, "COURSE_SEARCH"


def handle_contact_search(user_input, extracted_info, data_dict):
    """ì—°ë½ì²˜ ì¡°íšŒ ì§ˆë¬¸ ì²˜ë¦¬"""
    major = extracted_info.get('major')
    majors_info = data_dict.get('majors', MAJORS_INFO)
    
    if majors_info.empty:
        return "ì „ê³µ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nğŸ“ ë¬¸ì˜: í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ERROR"
    
    if not major:
        user_clean = user_input.replace(' ', '')
        for _, row in majors_info.iterrows():
            m_name = str(row['ì „ê³µëª…'])
            if m_name.replace(' ', '') in user_clean or user_clean in m_name.replace(' ', ''):
                major = m_name
                break
    
    if not major:
        return """## ğŸ“ ì—°ë½ì²˜ ì¡°íšŒ

ì–´ë–¤ ì „ê³µì˜ ì—°ë½ì²˜ë¥¼ ì°¾ìœ¼ì‹œë‚˜ìš”?

ğŸ’¡ **ì˜ˆì‹œ ì§ˆë¬¸:**
- "ê²½ì˜í•™ì „ê³µ ì—°ë½ì²˜ ì•Œë ¤ì¤˜"
- "ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ì „ê³µ ì‚¬ë¬´ì‹¤ ìœ„ì¹˜"

ğŸ“ ë¬¸ì˜: í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.""", "CONTACT_SEARCH"
    
    result = majors_info[majors_info['ì „ê³µëª…'].str.contains(major.replace('ì „ê³µ', ''), case=False, na=False)]
    
    if result.empty:
        return f"'{major}' ì—°ë½ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nğŸ“ ë¬¸ì˜: í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ERROR"
    
    row = result.iloc[0]
    
    response = f"## ğŸ“ {row['ì „ê³µëª…']} ì—°ë½ì²˜\n\n"
    response += "| í•­ëª© | ì •ë³´ |\n"
    response += "|------|------|\n"
    response += f"| **ì „ê³µëª…** | {row['ì „ê³µëª…']} |\n"
    response += f"| **ì—°ë½ì²˜** | {row.get('ì—°ë½ì²˜', '-')} |\n"
    response += f"| **ìœ„ì¹˜** | {row.get('ìœ„ì¹˜', '-')} |\n"
    
    homepage = row.get('í™ˆí˜ì´ì§€', '-')
    if pd.notna(homepage) and homepage != '-':
        response += f"| **í™ˆí˜ì´ì§€** | [{homepage}]({homepage}) |\n"
    
    return response, "CONTACT_SEARCH"


def handle_recommendation(user_input, extracted_info, data_dict):
    """ì¶”ì²œ ì§ˆë¬¸ ì²˜ë¦¬"""
    user_info = extract_user_info_for_recommendation(user_input, data_dict)
    
    if user_info.get('has_all_info'):
        result = calculate_multi_major_recommendation(
            user_info['admission_year'],
            user_info['primary_major'],
            user_info['completed_required'],
            user_info['completed_elective'],
            data_dict
        )
        return result, "RECOMMENDATION"
    else:
        missing = user_info.get('missing', [])
        
        response = "## ğŸ¯ ë§ì¶¤í˜• ë‹¤ì „ê³µ ì¶”ì²œ\n\n"
        response += "ì •í™•í•œ ì¶”ì²œì„ ìœ„í•´ ì•„ë˜ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤:\n\n"
        
        if 'admission_year' in missing:
            response += "- **ê¸°ì¤€í•™ë²ˆ** (ì˜ˆ: 2022í•™ë²ˆ)\n"
        if 'primary_major' in missing:
            response += "- **í˜„ì¬ ë³¸ì „ê³µ** (ì˜ˆ: ê²½ì˜í•™ì „ê³µ)\n"
        if 'completed_required' in missing:
            response += "- **ì´ìˆ˜í•œ ì „ê³µí•„ìˆ˜ í•™ì **\n"
        if 'completed_elective' in missing:
            response += "- **ì´ìˆ˜í•œ ì „ê³µì„ íƒ í•™ì **\n"
        
        response += "\nğŸ’¡ **ì˜ˆì‹œ ì§ˆë¬¸:**\n"
        response += '"ì €ëŠ” 2022í•™ë²ˆ ê²½ì˜í•™ì „ê³µì´ê³ , ì „ê³µí•„ìˆ˜ 3í•™ì , ì „ê³µì„ íƒ 9í•™ì  ë“¤ì—ˆì–´ìš”. ë‹¤ì „ê³µ ì¶”ì²œí•´ì£¼ì„¸ìš”!"\n\n'
        response += CONTACT_MESSAGE
        
        return response, "RECOMMENDATION"


def calculate_multi_major_recommendation(admission_year, primary_major, completed_required, completed_elective, data_dict):
    """í•™ìƒì˜ ì´ìˆ˜ í˜„í™©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì „ê³µ ì¶”ì²œ"""
    
    result = "## ğŸ“ ë§ì¶¤í˜• ë‹¤ì „ê³µ ì¶”ì²œ ê²°ê³¼\n\n"
    result += f"**ğŸ“‹ ì…ë ¥ ì •ë³´**\n"
    result += f"- ê¸°ì¤€í•™ë²ˆ: {admission_year}í•™ë²ˆ\n"
    result += f"- ë³¸ì „ê³µ: {primary_major}\n"
    result += f"- ì´ìˆ˜ í˜„í™©: ì „í•„ {completed_required}í•™ì , ì „ì„  {completed_elective}í•™ì  (ì´ {completed_required + completed_elective}í•™ì )\n\n"
    
    primary_req = data_dict.get('primary_req', PRIMARY_REQ)
    grad_req = data_dict.get('grad_req', GRADUATION_REQ)
    
    if primary_req.empty:
        return result + "âš ï¸ ë³¸ì „ê³µ ì´ìˆ˜ìš”ê±´ ë°ì´í„°ê°€ ì—†ì–´ ì¶”ì²œì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
    
    # ë³¸ì „ê³µ ë°ì´í„° í•„í„°ë§
    primary_data = primary_req[primary_req['ì „ê³µëª…'] == primary_major].copy()
    
    if primary_data.empty:
        return result + f"âš ï¸ '{primary_major}' ì „ê³µì˜ ì´ìˆ˜ìš”ê±´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    primary_data['ê¸°ì¤€í•™ë²ˆ'] = pd.to_numeric(primary_data['ê¸°ì¤€í•™ë²ˆ'], errors='coerce')
    applicable_primary = primary_data[primary_data['ê¸°ì¤€í•™ë²ˆ'] <= admission_year]
    
    if applicable_primary.empty:
        return result + f"âš ï¸ {admission_year}í•™ë²ˆì— í•´ë‹¹í•˜ëŠ” ë³¸ì „ê³µ ì´ìˆ˜ìš”ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì œë„ë³„ ë¶„ì„
    programs_to_analyze = ["ë³µìˆ˜ì „ê³µ", "ë¶€ì „ê³µ", "ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ", "ì—°ê³„ì „ê³µ"]
    recommendations = []
    
    result += "### ğŸ“Š ì œë„ë³„ í•™ì  ë¶„ì„\n\n"
    result += "| ì œë„ | ë³¸ì „ê³µ ë³€ê²½ | ë‚¨ì€ ë³¸ì „ê³µ | ë‹¤ì „ê³µ ì´ìˆ˜ | ì´ ì¶”ê°€ í•™ì  | í‰ê°€ |\n"
    result += "|------|------------|-----------|-----------|------------|------|\n"
    
    for program in programs_to_analyze:
        program_primary = applicable_primary[applicable_primary['ì œë„ìœ í˜•'].str.contains(program, na=False)]
        
        if program_primary.empty:
            continue
        
        program_primary = program_primary.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False)
        primary_row = program_primary.iloc[0]
        
        new_primary_required = int(primary_row.get('ë³¸ì „ê³µ_ì „ê³µí•„ìˆ˜', 0))
        new_primary_elective = int(primary_row.get('ë³¸ì „ê³µ_ì „ê³µì„ íƒ', 0))
        new_primary_total = int(primary_row.get('ë³¸ì „ê³µ_ê³„', 0))
        
        remaining_primary_required = max(0, new_primary_required - completed_required)
        remaining_primary_elective = max(0, new_primary_elective - completed_elective)
        remaining_primary_total = remaining_primary_required + remaining_primary_elective
        
        # ë‹¤ì „ê³µ ê¸°ë³¸ í•™ì 
        multi_credits = {
            "ë³µìˆ˜ì „ê³µ": 36,
            "ë¶€ì „ê³µ": 21,
            "ìœµí•©ì „ê³µ": 36,
            "ìœµí•©ë¶€ì „ê³µ": 21,
            "ì—°ê³„ì „ê³µ": 36
        }
        multi_total = multi_credits.get(program, 36)
        
        total_remaining = remaining_primary_total + multi_total
        
        if total_remaining <= 40:
            rating = "ğŸŸ¢ ë§¤ìš° ìœ ë¦¬"
        elif total_remaining <= 55:
            rating = "ğŸŸ¡ ë³´í†µ"
        else:
            rating = "ğŸ”´ ë¶€ë‹´ í¼"
        
        recommendations.append({
            'program': program,
            'remaining_primary_total': remaining_primary_total,
            'multi_total': multi_total,
            'total_remaining': total_remaining,
            'rating': rating
        })
        
        result += f"| {program} | {new_primary_total}í•™ì  | {remaining_primary_total}í•™ì  | {multi_total}í•™ì  | **{total_remaining}í•™ì ** | {rating} |\n"
    
    result += "\n"
    
    if recommendations:
        recommendations.sort(key=lambda x: x['total_remaining'])
        
        result += "### ğŸŒŸ ì¶”ì²œ ìˆœìœ„\n\n"
        for idx, rec in enumerate(recommendations[:3], 1):
            result += f"**{idx}ìˆœìœ„: {rec['program']}** - ì´ {rec['total_remaining']}í•™ì  {rec['rating']}\n"
        
        result += "\n"
    
    result += "### ğŸ¯ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ (ì†Œë‹¨ìœ„ì „ê³µ) - ì¶”ê°€ ì¶”ì²œ\n"
    result += "- **íŠ¹ì§•**: ë³¸ì „ê³µ í•™ì  ê°ë©´ ì—†ìŒ\n"
    result += "- **ì¶”ê°€ í•™ì **: 12~18í•™ì \n"
    result += "- **ì¥ì **: ë‹¤ë¥¸ ë‹¤ì „ê³µê³¼ ë³‘í–‰ ê°€ëŠ¥\n\n"
    
    result += "---\n"
    result += "âš ï¸ ìì„¸í•œ ë‚´ìš©ì€ í•™êµ í™ˆí˜ì´ì§€ **[í•™ì‚¬ê³µì§€](https://www.hknu.ac.kr/kor/562/subview.do)**ë¥¼ ì°¸ê³ í•˜ê±°ë‚˜\n\n"
    result += CONTACT_MESSAGE
    
    return result


def extract_user_info_for_recommendation(user_input, data_dict):
    """ì¶”ì²œì„ ìœ„í•œ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ"""
    user_info = {'missing': []}
    
    majors_list = []
    if 'primary_req' in data_dict and not data_dict['primary_req'].empty:
        majors_list = data_dict['primary_req']['ì „ê³µëª…'].unique().tolist()
    
    year_match = re.search(r'(20\d{2})[í•™ë…„ë²ˆ]|(\d{2})[í•™ë…„ë²ˆ]', user_input)
    if year_match:
        year = year_match.group(1) if year_match.group(1) else f"20{year_match.group(2)}"
        user_info['admission_year'] = int(year)
    else:
        user_info['missing'].append('admission_year')
    
    for major in majors_list:
        if major in user_input:
            user_info['primary_major'] = major
            break
    
    if 'primary_major' not in user_info:
        major_pattern = r'([ê°€-í£]+(?:í•™|ê³µí•™|ê³¼í•™))ì „ê³µ'
        major_matches = re.findall(major_pattern, user_input)
        if major_matches:
            user_info['primary_major'] = major_matches[0] + "ì „ê³µ"
        else:
            user_info['missing'].append('primary_major')
    
    required_patterns = [
        r'ì „[ê³µ]?í•„[ìˆ˜]?\s*(\d+)\s*í•™ì ',
        r'í•„ìˆ˜\s*(\d+)\s*í•™ì ',
        r'ì „í•„\s*(\d+)',
        r'ì „ê³µí•„ìˆ˜\s*(\d+)',
    ]
    for pattern in required_patterns:
        match = re.search(pattern, user_input)
        if match:
            user_info['completed_required'] = int(match.group(1))
            break
    if 'completed_required' not in user_info:
        user_info['missing'].append('completed_required')
    
    elective_patterns = [
        r'ì „[ê³µ]?ì„ [íƒ]?\s*(\d+)\s*í•™ì ',
        r'ì„ íƒ\s*(\d+)\s*í•™ì ',
        r'ì „ì„ \s*(\d+)',
        r'ì „ê³µì„ íƒ\s*(\d+)',
    ]
    for pattern in elective_patterns:
        match = re.search(pattern, user_input)
        if match:
            user_info['completed_elective'] = int(match.group(1))
            break
    if 'completed_elective' not in user_info:
        user_info['missing'].append('completed_elective')
    
    user_info['has_all_info'] = len(user_info['missing']) == 0
    
    return user_info


def handle_greeting(user_input, extracted_info, data_dict):
    """ì¸ì‚¬ ì²˜ë¦¬"""
    response = """## ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”!

**í•œê²½êµ­ë¦½ëŒ€í•™êµ ë‹¤ì „ê³µ(ìœ ì—°í•™ì‚¬ì œë„) ì•ˆë‚´ AIì±—ë´‡**ì…ë‹ˆë‹¤.

---

### ğŸ¯ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?

| ì§ˆë¬¸ ìœ í˜• | ì˜ˆì‹œ |
|----------|------|
| ğŸ“ ì‹ ì²­ | "ì‹ ì²­ ìê²©ì´ ë­ì•¼?" / "ì–¸ì œ ì‹ ì²­í•´?" |
| ğŸ“Š ë¹„êµ | "ë³µìˆ˜ì „ê³µì´ë‘ ë¶€ì „ê³µ ì°¨ì´ì " |
| ğŸ“– í•™ì  | "ë¶€ì „ê³µ ëª‡ í•™ì  ë“¤ì–´ì•¼ í•´?" |
| ğŸ¯ ì¶”ì²œ | "ë‚˜í•œí…Œ ë§ëŠ” ë‹¤ì „ê³µ ì¶”ì²œí•´ì¤˜" |
| ğŸ“ ì—°ë½ì²˜ | "ê²½ì˜í•™ì „ê³µ ì‚¬ë¬´ì‹¤ ë²ˆí˜¸" |

---

ğŸ’¡ **Tip**: ìœ„ì˜ **'ğŸ’¡ ì–´ë–¤ ì§ˆë¬¸ì„ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë‚˜ìš”?'**ë¥¼ í´ë¦­í•˜ë©´ ì˜ˆì‹œ ì§ˆë¬¸ì„ ë°”ë¡œ ì„ íƒí•  ìˆ˜ ìˆì–´ìš”!

ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š"""
    
    return response, "GREETING"


def handle_blocked(user_input, extracted_info, data_dict):
    """ìš•ì„¤/ë¶€ì ì ˆí•œ ì§ˆë¬¸ ì°¨ë‹¨"""
    response = """## âš ï¸ ì ê¹ë§Œìš”!

ë¶€ì ì ˆí•œ í‘œí˜„ì´ ê°ì§€ë˜ì—ˆì–´ìš”.

ì €ëŠ” **í•œê²½êµ­ë¦½ëŒ€í•™êµ í•™ìƒë“¤ì„ ë•ê¸° ìœ„í•œ AIì±—ë´‡**ì´ì—ìš”.
ë‹¤ì „ê³µ ê´€ë ¨ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ì¹œì ˆí•˜ê²Œ ë‹µë³€ë“œë¦´ê²Œìš”! ğŸ˜Š

---

ğŸ’¡ **ì´ëŸ° ì§ˆë¬¸ì€ ì–´ë– ì„¸ìš”?**
- "ë³µìˆ˜ì „ê³µ ì‹ ì²­ ìê²©ì´ ë­ì•¼?"
- "ë¶€ì „ê³µì´ë‘ ë³µìˆ˜ì „ê³µ ì°¨ì´ì  ì•Œë ¤ì¤˜"
- "ê²½ì˜í•™ì „ê³µ ì—°ë½ì²˜ ì•Œë ¤ì¤˜"

"""
    return response, "BLOCKED"


def handle_out_of_scope(user_input, extracted_info, data_dict):
    """ë²”ìœ„ ì™¸ ì§ˆë¬¸ ì²˜ë¦¬ - ë‹¤ì „ê³µê³¼ ë¬´ê´€í•œ ì§ˆë¬¸"""
    response = """## ğŸš« ëª¨ë¦…ë‹ˆë‹¤

ì €ëŠ” **í•œê²½êµ­ë¦½ëŒ€í•™êµ ë‹¤ì „ê³µ(ìœ ì—°í•™ì‚¬ì œë„) ì „ìš© AIì±—ë´‡**ì´ì—ìš”.
í•´ë‹¹ ì§ˆë¬¸ì€ ì œê°€ ë‹µë³€ë“œë¦¬ê¸° ì–´ë ¤ì›Œìš”.

---

### ğŸ’¬ ì´ëŸ° ì§ˆë¬¸ì€ ë‹µë³€í•  ìˆ˜ ìˆì–´ìš”!

| ì¹´í…Œê³ ë¦¬ | ì§ˆë¬¸ ì˜ˆì‹œ |
|---------|----------|
| ğŸ“ **ì‹ ì²­ ê´€ë ¨** | ì‹ ì²­ ìê²©ì´ ë­ì•¼? / ì‹ ì²­ ê¸°ê°„ ì–¸ì œì•¼? / ì–´ë–»ê²Œ ì‹ ì²­í•´? |
| ğŸ”„ **ë³€ê²½/í¬ê¸°** | ë‹¤ì „ê³µ í¬ê¸°í•˜ë ¤ë©´? / ë³µìˆ˜ì „ê³µì—ì„œ ë¶€ì „ê³µìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆì–´? |
| ğŸ“Š **ì œë„ ë¹„êµ** | ë³µìˆ˜ì „ê³µì´ë‘ ë¶€ì „ê³µ ì°¨ì´ê°€ ë­ì•¼? / ìœµí•©ì „ê³µì´ ë­ì•¼? |
| ğŸ“– **í•™ì  ì •ë³´** | ë³µìˆ˜ì „ê³µ ëª‡ í•™ì ì´ì•¼? / ë³¸ì „ê³µ í•™ì  ë³€í•´? |
| ğŸ¯ **ë§ì¶¤ ì¶”ì²œ** | 2022í•™ë²ˆ ê²½ì˜í•™ì „ê³µì¸ë° ë‹¤ì „ê³µ ì¶”ì²œí•´ì¤˜ |
| ğŸ“ **ì—°ë½ì²˜** | ê²½ì˜í•™ì „ê³µ ì‚¬ë¬´ì‹¤ ì „í™”ë²ˆí˜¸ / ì»´í“¨í„°ê³µí•™ì „ê³µ ì—°ë½ì²˜ |
| ğŸ“š **êµê³¼ëª©** | ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ì „ê³µ ì–´ë–¤ ê³¼ëª© ë“¤ì–´? |

---

### ğŸˆ ë¹ ë¥¸ ì‹œì‘

ğŸ‘† **ìœ„ì˜ 'ğŸ’¡ ì–´ë–¤ ì§ˆë¬¸ì„ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë‚˜ìš”?'**ë¥¼ í´ë¦­í•´ì„œ ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•´ë³´ì„¸ìš”!

**ì‚¬ì´ë“œë°” ë©”ë‰´**ì—ì„œë„ ë‹¤ìŒì„ ì´ìš©í•  ìˆ˜ ìˆì–´ìš”:
- ğŸ“Š **'ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´'** â†’ ì œë„ë³„ ìƒì„¸ ì •ë³´ í™•ì¸
- â“ **'FAQ'** â†’ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ê²€ìƒ‰

"""
    return response, "OUT_OF_SCOPE"


def get_ai_context(user_input, data_dict):
    """AI ì»¨í…ìŠ¤íŠ¸ ìƒì„± (RAG)"""
    context = ""
    programs = data_dict.get('programs', PROGRAM_INFO)
    
    for p_name, p_info in programs.items():
        context += f"\n[{p_name}]\n"
        context += f"- ì„¤ëª…: {p_info.get('description', '-')}\n"
        context += f"- ì´ìˆ˜í•™ì : {p_info.get('credits_multi', '-')}\n"
        context += f"- ì‹ ì²­ìê²©: {p_info.get('qualification', '-')}\n"
    
    return context


def get_faq_context(user_input, data_dict):
    """FAQ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
    faq_data = data_dict.get('faq', FAQ_DATA)
    
    if not faq_data:
        return ""
    
    context = "\n[ê´€ë ¨ FAQ]\n"
    count = 0
    
    for faq in faq_data:
        q = faq.get('ì§ˆë¬¸', '')
        a = faq.get('ë‹µë³€', '')
        
        q_clean = q.replace(' ', '').lower()
        if any(kw in q_clean for kw in ['ì‹ ì²­', 'ìê²©', 'í•™ì ', 'ê¸°ê°„', 'ë°©ë²•', 'í¬ê¸°', 'ë³€ê²½']):
            context += f"Q: {q}\nA: {a}\n\n"
            count += 1
            if count >= 3:
                break
    
    return context if count > 0 else ""


def handle_general(user_input, extracted_info, data_dict):
    """ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ - AIì—ê²Œ ìœ„ì„"""
    context = get_ai_context(user_input, data_dict)
    faq_context = get_faq_context(user_input, data_dict)
    
    prompt = f"""ë‹¹ì‹ ì€ í•œê²½êµ­ë¦½ëŒ€í•™êµ ë‹¤ì „ê³µ ì•ˆë‚´ AIì…ë‹ˆë‹¤.

í•™ìƒ ì§ˆë¬¸: {user_input}

[ì°¸ê³  ë°ì´í„°]
{context[:4000] if context else "ì—†ìŒ"}

{faq_context if faq_context else ""}

ğŸ’¡ **ê·œì¹™:**
1. ë°˜ë“œì‹œ '~ìŠµë‹ˆë‹¤', '~í•©ë‹ˆë‹¤'ì²´ ì‚¬ìš©
2. ë°ì´í„°ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©
3. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ "ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€(031-670-5035)ìœ¼ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”"
4. ê°„ê²°í•˜ê²Œ 200ì ì´ë‚´ë¡œ ë‹µë³€
"""
    
    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=prompt,
            config={
                'system_instruction': 'í•œê²½êµ­ë¦½ëŒ€í•™êµ ë‹¤ì „ê³µ ì•ˆë‚´ AIì…ë‹ˆë‹¤. ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.',
                'temperature': 0.3,
            }
        )
        if response and response.text:
            return response.text, "GENERAL"
    except Exception as e:
        pass
    
    return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\nğŸ“ ë¬¸ì˜: ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ERROR"


# í•¸ë“¤ëŸ¬ ë§¤í•‘
INTENT_HANDLERS = {
    'QUALIFICATION': handle_qualification,
    'APPLICATION_PERIOD': handle_application_period,
    'APPLICATION_METHOD': handle_application_method,
    'CANCEL': handle_cancel,
    'CHANGE': handle_change,
    'PROGRAM_COMPARISON': handle_program_comparison,
    'CREDIT_INFO': handle_credit_info,
    'PROGRAM_INFO': handle_program_info,
    'COURSE_SEARCH': handle_course_search,
    'CONTACT_SEARCH': handle_contact_search,
    'RECOMMENDATION': handle_recommendation,
    'GREETING': handle_greeting,
    'BLOCKED': handle_blocked,
    'OUT_OF_SCOPE': handle_out_of_scope,
    'GENERAL': handle_general,
}



def generate_ai_response(user_input, chat_history, data_dict):
    """í†µí•© ì‘ë‹µ ìƒì„±"""
    intent, method, extracted_info = classify_intent(user_input)
    
    # ë””ë²„ê·¸ ì •ë³´ (ê°œë°œìš©)
    # st.caption(f"ğŸ” ì˜ë„: {intent} | ë¶„ë¥˜ë°©ë²•: {method}")
    
    handler = INTENT_HANDLERS.get(intent, handle_general)
    response, response_type = handler(user_input, extracted_info, data_dict)
    
    return response, response_type


# ============================================================
# ğŸ“Š ì´ìˆ˜ì²´ê³„ë„ ë° ê³¼ëª© í‘œì‹œ í•¨ìˆ˜
# ============================================================

def display_curriculum_image(major, program_type):
    """ì´ìˆ˜ì²´ê³„ë„/ê³¼ì • ì•ˆë‚´ ì´ë¯¸ì§€ í‘œì‹œ
    - ìœµí•©ì „ê³µ: ì´ìˆ˜ì²´ê³„ë„ ì´ë¯¸ì§€
    - ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬): ê³¼ì • ì•ˆë‚´ ì´ë¯¸ì§€
    """
    # ìœµí•©ì „ê³µì´ë‚˜ ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)ë§Œ ì´ë¯¸ì§€ í‘œì‹œ
    is_fusion = program_type == "ìœµí•©ì „ê³µ"
    is_micro = "ì†Œë‹¨ìœ„" in program_type or "ë§ˆì´í¬ë¡œ" in program_type
    
    if not is_fusion and not is_micro:
        return
    
    if CURRICULUM_MAPPING.empty:
        return
    
    # ì œë„ìœ í˜• ë§¤ì¹­
    def match_program_type_for_image(type_value):
        type_str = str(type_value).strip().lower()
        
        if is_fusion:
            return "ìœµí•©ì „ê³µ" in type_str and "ìœµí•©ë¶€ì „ê³µ" not in type_str
        
        if is_micro:
            return any(kw in type_str for kw in ['ì†Œë‹¨ìœ„', 'ë§ˆì´í¬ë¡œ', 'md'])
        
        return False
    
    # ì „ê³µëª… ì •ì œ (í•™ë¶€ëª… ì œê±°)
    clean_major = major
    if ' ' in major:
        parts = major.split(' ')
        if len(parts) >= 2 and 'í•™ë¶€' in parts[0]:
            clean_major = ' '.join(parts[1:])
    
    # 1. ì •í™•í•œ ë§¤ì¹­ ì‹œë„
    filtered = CURRICULUM_MAPPING[
        (CURRICULUM_MAPPING['ì „ê³µëª…'] == clean_major) & 
        (CURRICULUM_MAPPING['ì œë„ìœ í˜•'].apply(match_program_type_for_image))
    ]
    
    # 2. ì›ë³¸ ì „ê³µëª…ìœ¼ë¡œ ì‹œë„
    if filtered.empty and clean_major != major:
        filtered = CURRICULUM_MAPPING[
            (CURRICULUM_MAPPING['ì „ê³µëª…'] == major) & 
            (CURRICULUM_MAPPING['ì œë„ìœ í˜•'].apply(match_program_type_for_image))
        ]
    
    # 3. ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ì „ê³µëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ)
    if filtered.empty:
        # "ìŠ¤ë§ˆíŠ¸íŒœì „ë¬¸ê°€ê³¼ì •" -> "ìŠ¤ë§ˆíŠ¸íŒœ"
        keywords = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '').replace('ì „ë¬¸ê°€', '')
        if len(keywords) >= 2:
            filtered = CURRICULUM_MAPPING[
                (CURRICULUM_MAPPING['ì „ê³µëª…'].str.contains(keywords[:4], na=False)) & 
                (CURRICULUM_MAPPING['ì œë„ìœ í˜•'].apply(match_program_type_for_image))
            ]
    
    # 4. ì œë„ìœ í˜•ë§Œìœ¼ë¡œ ì „ê³µëª… ì°¾ê¸° (curriculum_mappingì—ì„œ)
    if filtered.empty:
        type_matched = CURRICULUM_MAPPING[CURRICULUM_MAPPING['ì œë„ìœ í˜•'].apply(match_program_type_for_image)]
        for _, row in type_matched.iterrows():
            cm_major = str(row['ì „ê³µëª…'])
            # ì„ íƒí•œ ì „ê³µëª…ê³¼ curriculum_mappingì˜ ì „ê³µëª…ì´ ì„œë¡œ í¬í•¨ ê´€ê³„ì¸ì§€ í™•ì¸
            if clean_major in cm_major or cm_major in clean_major:
                filtered = type_matched[type_matched['ì „ê³µëª…'] == cm_major]
                break
            # í‚¤ì›Œë“œ ë¹„êµ
            cm_keyword = cm_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '')[:4]
            clean_keyword = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '')[:4]
            if cm_keyword == clean_keyword:
                filtered = type_matched[type_matched['ì „ê³µëª…'] == cm_major]
                break
    
    if not filtered.empty:
        filename = filtered.iloc[0]['íŒŒì¼ëª…']
        if pd.notna(filename) and str(filename).strip():
            image_path = f"{CURRICULUM_IMAGES_PATH}/{filename}"
            if os.path.exists(image_path):
                if is_fusion:
                    caption = f"{clean_major} ì´ìˆ˜ì²´ê³„ë„"
                else:
                    caption = f"{clean_major} ê³¼ì • ì•ˆë‚´"
                st.image(image_path, caption=caption)
            else:
                st.caption(f"ğŸ“· ì´ë¯¸ì§€ íŒŒì¼ ì¤€ë¹„ ì¤‘: {filename}")


def display_courses(major, program_type):
    """ê³¼ëª© ì •ë³´ í‘œì‹œ - í•™ë…„ë³„/í•™ê¸°ë³„/ì´ìˆ˜êµ¬ë¶„ë³„ ì •ë¦¬ + ì—°ë½ì²˜"""
    if COURSES_DATA.empty:
        st.info("êµê³¼ëª© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # ì œë„ìœ í˜• ë§¤ì¹­ í•¨ìˆ˜
    is_micro = "ì†Œë‹¨ìœ„" in program_type or "ë§ˆì´í¬ë¡œ" in program_type
    
    def match_program_type_for_courses(type_value):
        type_str = str(type_value).strip().lower()
        
        if is_micro:
            return any(kw in type_str for kw in ['ì†Œë‹¨ìœ„', 'ë§ˆì´í¬ë¡œ', 'md'])
        
        if program_type == "ë¶€ì „ê³µ":
            return "ë¶€ì „ê³µ" in type_str and "ìœµí•©ë¶€ì „ê³µ" not in type_str
        
        if program_type == "ìœµí•©ì „ê³µ":
            return "ìœµí•©ì „ê³µ" in type_str and "ìœµí•©ë¶€ì „ê³µ" not in type_str
        
        return program_type in type_str
    
    # ì „ê³µëª… ì •ì œ (í•™ë¶€ëª… ì œê±°)
    clean_major = major
    if ' ' in major:
        parts = major.split(' ')
        if len(parts) >= 2 and 'í•™ë¶€' in parts[0]:
            clean_major = ' '.join(parts[1:])
    
    # 1. ì •í™•í•œ ë§¤ì¹­
    courses = COURSES_DATA[
        (COURSES_DATA['ì „ê³µëª…'] == clean_major) & 
        (COURSES_DATA['ì œë„ìœ í˜•'].apply(match_program_type_for_courses))
    ]
    
    # 2. ì›ë³¸ ì „ê³µëª…ìœ¼ë¡œ ì‹œë„
    if courses.empty and clean_major != major:
        courses = COURSES_DATA[
            (COURSES_DATA['ì „ê³µëª…'] == major) & 
            (COURSES_DATA['ì œë„ìœ í˜•'].apply(match_program_type_for_courses))
        ]
    
    # 3. ë¶€ë¶„ ë§¤ì¹­ (ì „ê³µëª… í‚¤ì›Œë“œ)
    if courses.empty:
        keyword = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '').replace('ì „ë¬¸ê°€', '')
        if len(keyword) >= 2:
            courses = COURSES_DATA[
                (COURSES_DATA['ì „ê³µëª…'].str.contains(keyword[:4], na=False)) & 
                (COURSES_DATA['ì œë„ìœ í˜•'].apply(match_program_type_for_courses))
            ]
    
    # 4. ì œë„ìœ í˜•ìœ¼ë¡œ ë¨¼ì € í•„í„°ë§ í›„ ì „ê³µëª… ì°¾ê¸°
    if courses.empty:
        type_matched = COURSES_DATA[COURSES_DATA['ì œë„ìœ í˜•'].apply(match_program_type_for_courses)]
        for course_major in type_matched['ì „ê³µëª…'].unique():
            cm_str = str(course_major)
            if clean_major in cm_str or cm_str in clean_major:
                courses = type_matched[type_matched['ì „ê³µëª…'] == course_major]
                clean_major = cm_str  # ì‹¤ì œ ì „ê³µëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                break
            cm_keyword = cm_str.replace('ì „ê³µ', '').replace('ê³¼ì •', '')[:4]
            clean_keyword = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '')[:4]
            if cm_keyword == clean_keyword:
                courses = type_matched[type_matched['ì „ê³µëª…'] == course_major]
                clean_major = cm_str
                break
    
    # ì œë„ìœ í˜• í‘œì‹œìš© ì •ì œ
    display_program_type = program_type
    if is_micro:
        display_program_type = "ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)"
    
    if not courses.empty:
        st.subheader(f"ğŸ“š ({display_program_type}) {clean_major} í¸ì„± êµê³¼ëª©(2025í•™ë…„ë„ êµìœ¡ê³¼ì • ê¸°ì¤€) ì•ˆë‚´")
        
        # í•™ë…„ë³„ íƒ­
        years = sorted([int(y) for y in courses['í•™ë…„'].unique() if pd.notna(y)])
        
        if years:
            tabs = st.tabs([f"{year}í•™ë…„" for year in years])
            
            for idx, year in enumerate(years):
                with tabs[idx]:
                    year_courses = courses[courses['í•™ë…„'] == year]
                    semesters = sorted([int(s) for s in year_courses['í•™ê¸°'].unique() if pd.notna(s)])
                    
                    for semester in semesters:
                        st.markdown(f"#### ğŸ“… {semester}í•™ê¸°")
                        
                        semester_courses = year_courses[year_courses['í•™ê¸°'] == semester]
                        
                        # ì´ìˆ˜êµ¬ë¶„ë³„ ê·¸ë£¹í™”
                        required_courses = semester_courses[semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('í•„ìˆ˜', na=False)]
                        elective_courses = semester_courses[semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('ì„ íƒ', na=False)]
                        other_courses = semester_courses[
                            ~semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('í•„ìˆ˜', na=False) & 
                            ~semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('ì„ íƒ', na=False)
                        ]
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if not required_courses.empty:
                                st.markdown("**ğŸ”´ ì „ê³µí•„ìˆ˜**")
                                for _, row in required_courses.iterrows():
                                    course_name = row.get('ê³¼ëª©ëª…', '')
                                    credits = row.get('í•™ì ', '')
                                    try:
                                        credits_str = f"{int(credits)}í•™ì "
                                    except:
                                        credits_str = ""
                                    st.write(f"â€¢ {course_name} ({credits_str})")
                        
                        with col2:
                            if not elective_courses.empty:
                                st.markdown("**ğŸŸ¢ ì „ê³µì„ íƒ**")
                                for _, row in elective_courses.iterrows():
                                    course_name = row.get('ê³¼ëª©ëª…', '')
                                    credits = row.get('í•™ì ', '')
                                    try:
                                        credits_str = f"{int(credits)}í•™ì "
                                    except:
                                        credits_str = ""
                                    st.write(f"â€¢ {course_name} ({credits_str})")
                        
                        if not other_courses.empty:
                            st.markdown("**ğŸ”µ ê¸°íƒ€**")
                            for _, row in other_courses.iterrows():
                                division = row.get('ì´ìˆ˜êµ¬ë¶„', '')
                                course_name = row.get('ê³¼ëª©ëª…', '')
                                credits = row.get('í•™ì ', '')
                                try:
                                    credits_str = f"{int(credits)}í•™ì "
                                except:
                                    credits_str = ""
                                st.write(f"â€¢ [{division}] {course_name} ({credits_str})")
                        
                        st.divider()
        
        # ì „ê³µ ì—°ë½ì²˜ í‘œì‹œ
        st.markdown("---")
        display_major_contact(clean_major)
        
        return True
    else:
        st.info(f"'{clean_major}' - '{display_program_type}'ì˜ êµê³¼ëª© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False


def display_major_contact(major):
    """ì „ê³µ ì—°ë½ì²˜ í‘œì‹œ"""
    if MAJORS_INFO.empty:
        return
    
    # ì „ê³µëª… ë§¤ì¹­
    contact_row = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'] == major]
    
    if contact_row.empty:
        # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
        keyword = major.replace('ì „ê³µ', '').replace('ê³¼ì •', '')[:4]
        contact_row = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'].str.contains(keyword, na=False)]
    
    if not contact_row.empty:
        row = contact_row.iloc[0]
        phone = row.get('ì—°ë½ì²˜', '')
        location = row.get('ì‚¬ë¬´ì‹¤ìœ„ì¹˜', '')
        
        contact_info = []
        if pd.notna(phone) and str(phone).strip():
            contact_info.append(f"ğŸ“ **ì—°ë½ì²˜**: {phone}")
        if pd.notna(location) and str(location).strip():
            contact_info.append(f"ğŸ“ **ì‚¬ë¬´ì‹¤**: {location}")
        
        if contact_info:
            st.info("**ğŸ“‹ ì „ê³µ ë¬¸ì˜ì²˜**\n\n" + "\n\n".join(contact_info))
        else:
            st.caption("ğŸ“ ë¬¸ì˜: í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# ============================================================
# ğŸ–¥ï¸ ë©”ì¸ UI
# ============================================================

def main():
    initialize_session_state()
    
    st.title(APP_TITLE)
    
    # === ì‚¬ì´ë“œë°” ===
    with st.sidebar:
        st.markdown(
            """
            <div style='text-align: center; padding: 10px 0;'>
                <h1 style='font-size: 3rem; margin-bottom: 0;'>ğŸ“</h1>
                <h3 style='margin-top: 0;'>HKNU ë‹¤ì „ê³µ ì•ˆë‚´</h3>
            </div>
            """, 
            unsafe_allow_html=True
        )
        
        menu = option_menu(
            menu_title=None,
            options=["AIì±—ë´‡ ìƒë‹´", "ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´", "FAQ"], 
            icons=["chat-dots-fill", "journal-bookmark-fill", "question-circle-fill"],
            default_index=0,
            styles={
                "container": {"padding": "0!important", "background-color": "#fafafa"},
                "icon": {"color": "orange", "font-size": "18px"}, 
                "nav-link": {"font-size": "16px", "text-align": "left", "margin":"0px"},
                "nav-link-selected": {"background-color": "#0091FF"},
            }
        )
        
        st.divider()
        
        with st.container(border=True):
            st.markdown("### ğŸ¤– AIì±—ë´‡ ì•ˆë‚´")
            st.info("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")
            # Semantic Router ìƒíƒœ í‘œì‹œ
            if SEMANTIC_ROUTER is not None:
                st.caption("ğŸ§  Semantic Router í™œì„±í™”")
            else:
                st.caption("âš¡ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ì¤‘")
            st.caption("* ì •ë³´ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤.")
        
        st.markdown("---")
        st.caption("â˜ í•™ì‚¬ì§€ì›íŒ€ 031-670-5035")
        st.caption("* Powered by Gemini 2.0")
    
    # === ë©”ì¸ ì½˜í…ì¸  ===
    
    if menu == "AIì±—ë´‡ ìƒë‹´":
        st.subheader("ğŸ’¬ AI ìƒë‹´ì›ê³¼ ëŒ€í™”í•˜ê¸°")
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼
        with st.expander("ğŸ’¡ ì–´ë–¤ ì§ˆë¬¸ì„ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë‚˜ìš”? (í´ë¦­)", expanded=False):
            st.markdown("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
            
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ ì‹ ì²­ ê´€ë ¨", "ğŸ“š ì œë„ ì•ˆë‚´", "ğŸ“ í•™ì /ì¶”ì²œ", "ğŸ“ ì „ê³µ/ê³¼ëª©"])
            
            questions_by_tab = {
                "tab1": [
                    "ì‹ ì²­ ìê²©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "ì‹ ì²­ ê¸°ê°„ì€ ì–¸ì œì¸ê°€ìš”?",
                    "ì‹ ì²­ ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
                    "ë‹¤ì „ê³µ í¬ê¸°ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
                ],
                "tab2": [
                    "ë³µìˆ˜ì „ê³µê³¼ ë¶€ì „ê³µ ì°¨ì´ì ",
                    "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ê°€ ë­ì•¼?",
                    "ìœµí•©ì „ê³µ ì„¤ëª…í•´ì¤˜",
                    "ì—°ê³„ì „ê³µì´ ë­”ê°€ìš”?"
                ],
                "tab3": [
                    "ì œë„ë³„ ì´ìˆ˜ í•™ì  ì•Œë ¤ì¤˜",
                    "ë³µìˆ˜ì „ê³µ í•˜ë©´ ë³¸ì „ê³µ í•™ì  ë³€í•´?",
                    "2022í•™ë²ˆ ê²½ì˜í•™ì „ê³µ, ì „í•„3í•™ì  ì „ì„ 9í•™ì . ë‹¤ì „ê³µ ì¶”ì²œí•´ì¤˜",
                    "ë¶€ì „ê³µì€ ëª‡ í•™ì  ì´ìˆ˜í•´ì•¼ í•´?"
                ],
                "tab4": [
                    "ê²½ì˜í•™ì „ê³µ ì—°ë½ì²˜",
                    "ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ì „ê³µ ì‚¬ë¬´ì‹¤ ìœ„ì¹˜",
                    "AIë°˜ë„ì²´ìœµí•©ì „ê³µ ì–´ë–¤ ê³¼ëª© ë“¤ì–´?",
                    "ë¹…ë°ì´í„°ìœµí•©ì „ê³µ êµê³¼ëª© ì•Œë ¤ì¤˜"
                ]
            }
            
            def handle_question_click(question):
                st.session_state.chat_history.append({"role": "user", "content": question})
                with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    response_text, res_type = generate_ai_response(
                        question,
                        st.session_state.chat_history[:-1],
                        ALL_DATA
                    )
                st.session_state.chat_history.append({
                    "role": "assistant", 
                    "content": response_text, 
                    "response_type": res_type
                })
                st.rerun()
            
            with tab1:
                cols = st.columns(2)
                for idx, q in enumerate(questions_by_tab["tab1"]):
                    if cols[idx % 2].button(f"ğŸ’¬ {q}", key=f"tab1_{idx}", use_container_width=True):
                        handle_question_click(q)
            
            with tab2:
                cols = st.columns(2)
                for idx, q in enumerate(questions_by_tab["tab2"]):
                    if cols[idx % 2].button(f"ğŸ’¬ {q}", key=f"tab2_{idx}", use_container_width=True):
                        handle_question_click(q)
            
            with tab3:
                cols = st.columns(2)
                for idx, q in enumerate(questions_by_tab["tab3"]):
                    if cols[idx % 2].button(f"ğŸ’¬ {q}", key=f"tab3_{idx}", use_container_width=True):
                        handle_question_click(q)
            
            with tab4:
                cols = st.columns(2)
                for idx, q in enumerate(questions_by_tab["tab4"]):
                    if cols[idx % 2].button(f"ğŸ’¬ {q}", key=f"tab4_{idx}", use_container_width=True):
                        handle_question_click(q)
        
        st.divider()
        
        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for chat in st.session_state.chat_history:
            role = "user" if chat["role"] == "user" else "assistant"
            avatar = "ğŸ§‘â€ğŸ“" if role == "user" else "ğŸ¤–"
            with st.chat_message(role, avatar=avatar):
                st.markdown(chat["content"])
        
        # ì…ë ¥ì°½
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            with st.chat_message("user", avatar="ğŸ§‘â€ğŸ“"):
                st.markdown(prompt)
            
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    response_text, res_type = generate_ai_response(
                        prompt, 
                        st.session_state.chat_history[:-1], 
                        ALL_DATA
                    )
                    st.markdown(response_text)
            
            st.session_state.chat_history.append({
                "role": "assistant", 
                "content": response_text, 
                "response_type": res_type
            })
            scroll_to_bottom()
    
    elif menu == "ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´":
        st.header("ğŸ“Š ì œë„ í•œëˆˆì— ë¹„êµ")

        # ì œë„ë³„ í•™ì  ì •ë³´ë¥¼ ì‹¤ì œ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
        def get_program_credits(program_name):
            """ì œë„ë³„ ë³¸ì „ê³µ/ë‹¤ì „ê³µ í•™ì  ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
            primary_credits = "-"
            multi_credits = "-"
            
            # ì œë„ëª… ë§¤í•‘ (UI í‘œì‹œëª… â†’ ë°ì´í„° ê²€ìƒ‰ìš©)
            program_mapping = {
                'ë³µìˆ˜ì „ê³µ': 'ë³µìˆ˜ì „ê³µ',
                'ë¶€ì „ê³µ': 'ë¶€ì „ê³µ',
                'ìœµí•©ì „ê³µ': 'ìœµí•©ì „ê³µ',
                'ìœµí•©ë¶€ì „ê³µ': 'ìœµí•©ë¶€ì „ê³µ',
                'ì—°ê³„ì „ê³µ': 'ì—°ê³„ì „ê³µ',
                'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬': 'ì†Œë‹¨ìœ„',
                'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •': 'ì†Œë‹¨ìœ„',
            }
            search_name = program_mapping.get(program_name, program_name)
            
            # ë³¸ì „ê³µ í•™ì  (primary_requirements.xlsxì—ì„œ)
            if 'primary_req' in ALL_DATA and not ALL_DATA['primary_req'].empty:
                primary_req = ALL_DATA['primary_req']
                filtered = primary_req[primary_req['ì œë„ìœ í˜•'].str.contains(search_name, na=False)]
                if not filtered.empty:
                    row = filtered.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False).iloc[0]
                    val = row.get('ë³¸ì „ê³µ_ê³„', 0)
                    if pd.notna(val):
                        try:
                            primary_credits = f"{int(val)}í•™ì "
                        except (ValueError, TypeError):
                            primary_credits = f"{val}í•™ì "
            
            # ë‹¤ì „ê³µ í•™ì  (graduation_requirements.xlsxì—ì„œ)
            if 'grad_req' in ALL_DATA and not ALL_DATA['grad_req'].empty:
                grad_req = ALL_DATA['grad_req']
                filtered = grad_req[grad_req['ì œë„ìœ í˜•'].str.contains(search_name, na=False)]
                if not filtered.empty:
                    row = filtered.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False).iloc[0]
                    val = row.get('ë‹¤ì „ê³µ_ê³„', 0)
                    if pd.notna(val):
                        try:
                            multi_credits = f"{int(val)}í•™ì "
                        except (ValueError, TypeError):
                            multi_credits = f"{val}í•™ì "
            
            return primary_credits, multi_credits

        if 'programs' in ALL_DATA and ALL_DATA['programs']:
            cols = st.columns(3)
            for idx, (program, info) in enumerate(ALL_DATA['programs'].items()):
                with cols[idx % 3]:
                    desc = info.get('description', 'ì„¤ëª… ì—†ìŒ')
                    if pd.isna(desc) or desc == '':
                        desc = 'ì„¤ëª… ì—†ìŒ'
                    # programs.xlsxì—ì„œ í•™ì  ì •ë³´ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
                    c_pri = info.get('credits_primary', '-')
                    c_mul = info.get('credits_multi', '-')
                    if pd.isna(c_pri) or c_pri == '':
                        c_pri = '-'
                    if pd.isna(c_mul) or c_mul == '':
                        c_mul = '-'
                    degree = info.get('degree', '-')
                    if pd.isna(degree) or degree == '':
                        degree = '-'
                    difficulty = info.get('difficulty', 'â­')
                    if pd.isna(difficulty) or difficulty == '':
                        difficulty = 'â­â­â­'
                    
                    # ê¸´ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
                    long_text_style = "overflow: hidden; text-overflow: ellipsis; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; line-height: 1.4; font-size: 12px;"

                    html_content = f"""
                    <div style="border: 1px solid #e5e7eb; border-radius: 14px; padding: 18px; background: white; box-shadow: 0 4px 6px rgba(0,0,0,0.05); min-height: 420px; margin-bottom: 20px; display: flex; flex-direction: column; justify-content: space-between;">
                        <div>
                            <h3 style="margin: 0 0 8px 0; color: #1f2937; font-size: 1.2rem;">ğŸ“ {program}</h3>
                            <p style="color: #6b7280; font-size: 13px; margin-bottom: 12px;">{desc}</p>
                            <hr style="margin: 12px 0; border: 0; border-top: 1px solid #e5e7eb;">
                            <div style="font-size: 14px; margin-bottom: 8px;">
                                <strong style="color: #374151;">ğŸ“– ì´ìˆ˜ í•™ì </strong>
                                <ul style="padding-left: 18px; margin: 4px 0; color: #4b5563; font-size: 12px;">
                                    <li style="margin-bottom: 4px;"><span style="font-weight:600; color:#374151;">ë³¸ì „ê³µ:</span> {c_pri}</li>
                                    <li><span style="font-weight:600; color:#374151;">ë‹¤ì „ê³µ:</span> {c_mul}</li>
                                </ul>
                            </div>
                        </div>
                        <div style="display: flex; justify-content: space-between; align-items: end; margin-top: 10px;">
                            <div style="max-width: 65%;">
                                <strong style="color: #374151; font-size: 14px;">ğŸ“œ í•™ìœ„ê¸°</strong><br>
                                <div style="font-size: 12px; color: #2563eb; background: #eff6ff; padding: 2px 6px; border-radius: 4px; {long_text_style}">{degree}</div>
                            </div>
                            <div style="text-align: right; min-width: 30%;">
                                <strong style="color: #374151; font-size: 14px;">ë‚œì´ë„</strong><br>
                                <span style="color: #f59e0b; font-size: 16px;">{difficulty}</span>
                            </div>
                        </div>
                    </div>"""
                    st.markdown(html_content, unsafe_allow_html=True)
        else:
            st.error("âŒ ì œë„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        st.divider()

        st.subheader("ğŸ” ìƒì„¸ ì •ë³´ ì¡°íšŒ")
        
        prog_keys = list(ALL_DATA['programs'].keys()) if 'programs' in ALL_DATA else []
        selected_program = st.selectbox("ìì„¸íˆ ì•Œì•„ë³¼ ì œë„ë¥¼ ì„ íƒí•˜ì„¸ìš”", prog_keys)
        
        if selected_program and 'programs' in ALL_DATA:
            info = ALL_DATA['programs'][selected_program]
            
            # programs.xlsxì—ì„œ í•™ì  ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            c_gen = info.get('credits_general', '-')
            c_pri = info.get('credits_primary', '-')
            c_mul = info.get('credits_multi', '-')
            if pd.isna(c_gen) or c_gen == '':
                c_gen = '-'
            if pd.isna(c_pri) or c_pri == '':
                c_pri = '-'
            if pd.isna(c_mul) or c_mul == '':
                c_mul = '-'
            
            tab1, tab2 = st.tabs(["ğŸ“ ê¸°ë³¸ ì •ë³´", "âœ… íŠ¹ì§• ë° ìœ ì˜ì‚¬í•­"])
            with tab1:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.info(f"**ê°œìš”**\n\n{info.get('description', '-')}")
                    st.subheader("ğŸ“– ì´ìˆ˜ í•™ì  ìƒì„¸")
                    st.markdown(f"""
- **êµì–‘:** {c_gen}
- **ì›ì „ê³µ:** {c_pri}
- **ë‹¤ì „ê³µ:** {c_mul}
                    """)
                    st.subheader("ğŸ“ ì¡¸ì—… ìš”ê±´")
                    st.markdown(f"- **ì¡¸ì—…ì¸ì¦:** {info.get('graduation_certification', '-')}")
                    st.markdown(f"- **ì¡¸ì—…ì‹œí—˜:** {info.get('graduation_exam', '-')}")

                with col2:
                    st.success(f"**ì‹ ì²­ ìê²©**\n\n{info.get('qualification', '-')}")
                    st.write(f"**í•™ìœ„ê¸° í‘œê¸°**\n\n{info.get('degree', '-')}")
            with tab2:
                for f in info.get('features', []): st.write(f"âœ”ï¸ {f}")
                if info.get('notes'): st.warning(f"**ğŸ’¡ ìœ ì˜ì‚¬í•­**: {info['notes']}")
            
            st.divider()

            # ì „ê³µëª… -> êµìœ¡ìš´ì˜ì „ê³µ ë§¤í•‘
            available_majors = {}
            
            # ğŸ”¥ ì •í™•í•œ ì œë„ìœ í˜• ë§¤ì¹­ í•¨ìˆ˜
            def match_program_type(type_value, selected_prog):
                type_str = str(type_value).strip()
                
                if "ì†Œë‹¨ìœ„" in selected_prog or "ë§ˆì´í¬ë¡œ" in selected_prog:
                    return any(kw in type_str.lower() for kw in ['ì†Œë‹¨ìœ„', 'ë§ˆì´í¬ë¡œ', 'md'])
                
                if selected_prog == "ë¶€ì „ê³µ":
                    return "ë¶€ì „ê³µ" in type_str and "ìœµí•©ë¶€ì „ê³µ" not in type_str
                
                if selected_prog == "ìœµí•©ì „ê³µ":
                    return "ìœµí•©ì „ê³µ" in type_str and "ìœµí•©ë¶€ì „ê³µ" not in type_str
                
                return selected_prog in type_str
            
            # ì „ê³µëª… ì •ì œ í•¨ìˆ˜ (í•™ë¶€ëª… ì œê±°: "AIìœµí•©í•™ë¶€ AIë¹…ë°ì´í„°ìœµí•©ì „ê³µ" -> "AIë¹…ë°ì´í„°ìœµí•©ì „ê³µ")
            def clean_major_name(major_name):
                if not major_name or pd.isna(major_name):
                    return major_name
                name = str(major_name).strip()
                if ' ' in name:
                    parts = name.split(' ')
                    if len(parts) >= 2 and 'í•™ë¶€' in parts[0]:
                        return ' '.join(parts[1:])
                return name
            
            if 'courses' in ALL_DATA and not ALL_DATA['courses'].empty:
                c_df = ALL_DATA['courses']
                if 'ì œë„ìœ í˜•' in c_df.columns:
                    mask = c_df['ì œë„ìœ í˜•'].apply(lambda x: match_program_type(x, selected_program))
                    for major in c_df[mask]['ì „ê³µëª…'].unique():
                        cleaned = clean_major_name(major)
                        if cleaned not in available_majors:
                            available_majors[cleaned] = None

            if 'curriculum' in ALL_DATA:
                 curr_df = ALL_DATA['curriculum']
                 if not curr_df.empty and 'ì œë„ìœ í˜•' in curr_df.columns:
                     mask = curr_df['ì œë„ìœ í˜•'].apply(lambda x: match_program_type(x, selected_program))
                     for major in curr_df[mask]['ì „ê³µëª…'].unique():
                         cleaned = clean_major_name(major)
                         if cleaned not in available_majors:
                             available_majors[cleaned] = None
            
            if 'majors' in ALL_DATA and not ALL_DATA['majors'].empty:
                m_df = ALL_DATA['majors']
                if 'ì œë„ìœ í˜•' in m_df.columns:
                    mask = m_df['ì œë„ìœ í˜•'].apply(lambda x: match_program_type(x, selected_program))
                    
                    for _, row in m_df[mask].iterrows():
                        major_name = clean_major_name(row['ì „ê³µëª…'])
                        edu_major = row.get('êµìœ¡ìš´ì˜ì „ê³µ', None)
                        
                        if pd.notna(edu_major) and str(edu_major).strip() not in ['', 'nan', '-']:
                            available_majors[major_name] = str(edu_major).strip()
                        elif major_name not in available_majors:
                            available_majors[major_name] = None
            
            # ì¤‘ë³µ ì „ê³µëª… ì œê±°
            def remove_duplicate_majors(majors_dict):
                major_names = list(majors_dict.keys())
                to_remove = set()
                
                for i, name1 in enumerate(major_names):
                    for j, name2 in enumerate(major_names):
                        if i != j:
                            if name1 in name2 and len(name2) > len(name1):
                                to_remove.add(name2)
                
                for name in to_remove:
                    if name in majors_dict:
                        del majors_dict[name]
                
                return majors_dict
            
            available_majors = remove_duplicate_majors(available_majors)

            if available_majors:
                target_programs = ["ë³µìˆ˜ì „ê³µ", "ë¶€ì „ê³µ", "ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ"]
                
                if selected_program in target_programs:
                    col_m1, col_m2 = st.columns(2)
                    with col_m1:
                        selected_major = st.selectbox(f"ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}", sorted(list(available_majors.keys())))
                    with col_m2:
                        all_majors_list = []
                        if 'primary_req' in ALL_DATA and not ALL_DATA['primary_req'].empty:
                            all_majors_list = sorted(ALL_DATA['primary_req']['ì „ê³µëª…'].unique().tolist())
                        my_primary_major = st.selectbox("ë‚˜ì˜ ë³¸ì „ê³µ (ì œ1ì „ê³µ)", ["ì„ íƒ ì•ˆ í•¨"] + all_majors_list)
                else:
                    if "ì†Œë‹¨ìœ„" in selected_program or "ë§ˆì´í¬ë¡œ" in selected_program:
                        field_groups = {}
                        major_display_map = {}
                        
                        for major_name, edu_major in available_majors.items():
                            major_lower = str(major_name).lower()
                            
                            if edu_major:
                                display_name = f"{major_name} ({edu_major})"
                            else:
                                display_name = major_name
                            
                            major_display_map[display_name] = major_name
                            
                            if any(k in major_lower for k in ['ì‹í’ˆ', 'ë†', 'ì›ì˜ˆ', 'ìƒëª…', 'ë°”ì´ì˜¤']):
                                field = "ğŸŒ¾ ë†ì—…Â·ì‹í’ˆÂ·ë°”ì´ì˜¤"
                            elif any(k in major_lower for k in ['ë””ì§€í„¸', 'ai', 'ì¸ê³µì§€ëŠ¥', 'ë°ì´í„°', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ict', 'ìŠ¤ë§ˆíŠ¸']):
                                field = "ğŸ’» ICTÂ·ë””ì§€í„¸"
                            elif any(k in major_lower for k in ['ê²½ì˜', 'ì°½ì—…', 'ë§ˆì¼€íŒ…', 'ê¸ˆìœµ', 'íšŒê³„']):
                                field = "ğŸ’¼ ê²½ì˜Â·ì°½ì—…"
                            elif any(k in major_lower for k in ['í™˜ê²½', 'ì—ë„ˆì§€', 'ê¸°í›„']):
                                field = "ğŸŒ í™˜ê²½Â·ì—ë„ˆì§€"
                            elif any(k in major_lower for k in ['ë””ìì¸', 'ë¯¸ë””ì–´', 'ì½˜í…ì¸ ', 'ë¬¸í™”']):
                                field = "ğŸ¨ ë””ìì¸Â·ë¬¸í™”Â·ì½˜í…ì¸ "
                            elif any(k in major_lower for k in ['ê¸€ë¡œë²Œ', 'êµ­ì œ', 'í†µìƒ', 'ë¬´ì—­']):
                                field = "ğŸŒ ê¸€ë¡œë²ŒÂ·êµ­ì œ"
                            elif any(k in major_lower for k in ['ê±´ê°•', 'ì˜ë£Œ', 'ë°”ì´ì˜¤í—¬ìŠ¤', 'ë³µì§€']):
                                field = "ğŸ¥ ê±´ê°•Â·ì˜ë£Œ"
                            else:
                                field = "ğŸ“š ê¸°íƒ€"
                            
                            if field not in field_groups:
                                field_groups[field] = []
                            field_groups[field].append(display_name)
                        
                        grouped_options = []
                        for field in sorted(field_groups.keys()):
                            grouped_options.append(f"â”â”â”â”â” {field} â”â”â”â”â”")
                            for display_name in sorted(field_groups[field]):
                                grouped_options.append(display_name)
                        
                        selected_option = st.selectbox(
                            f"ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}", 
                            grouped_options,
                            help="ë¶„ì•¼ë³„ë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŠµë‹ˆë‹¤"
                        )
                        
                        if selected_option.startswith("â”â”â”â”â”"):
                            st.warning("âš ï¸ êµ¬ë¶„ì„ ì€ ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ê³µëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            selected_major = None
                        else:
                            selected_major = major_display_map.get(selected_option, selected_option)
                    else:
                        selected_major = st.selectbox(f"ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}", sorted(list(available_majors.keys())))
                    
                    my_primary_major = "ì„ íƒ ì•ˆ í•¨"

                if selected_major:
                    if selected_program in target_programs:
                        current_year = datetime.now().year
                        admission_year = st.number_input(
                            "ë³¸ì¸ í•™ë²ˆ (ì…í•™ì—°ë„)", 
                            min_value=2018, 
                            max_value=current_year, 
                            value=current_year
                        )
                        
                        st.write("")
                        
                        col_left, col_right = st.columns(2)
                        
                        with col_left:
                            st.subheader(f"ğŸ¯ {selected_program}({selected_major}) ì´ìˆ˜ í•™ì  ê¸°ì¤€")
                            
                            if 'grad_req' in ALL_DATA and not ALL_DATA['grad_req'].empty:
                                req_data = ALL_DATA['grad_req'][
                                    (ALL_DATA['grad_req']['ì „ê³µëª…'] == selected_major) & 
                                    (ALL_DATA['grad_req']['ì œë„ìœ í˜•'].str.contains(selected_program, na=False))
                                ].copy()
                                
                                req_data['ê¸°ì¤€í•™ë²ˆ'] = pd.to_numeric(req_data['ê¸°ì¤€í•™ë²ˆ'], errors='coerce')
                                req_data = req_data.dropna(subset=['ê¸°ì¤€í•™ë²ˆ'])
                                applicable = req_data[req_data['ê¸°ì¤€í•™ë²ˆ'] <= admission_year]
                                
                                if not applicable.empty:
                                    applicable = applicable.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False)
                                    row = applicable.iloc[0]
                                    
                                    st.write(f"- ì „ê³µí•„ìˆ˜: **{int(row['ë‹¤ì „ê³µ_ì „ê³µí•„ìˆ˜'])}**í•™ì ")
                                    st.write(f"- ì „ê³µì„ íƒ: **{int(row['ë‹¤ì „ê³µ_ì „ê³µì„ íƒ'])}**í•™ì ")
                                    st.markdown(f"#### ğŸ‘‰ {selected_program} {int(row['ë‹¤ì „ê³µ_ê³„'])}í•™ì ")
                                else:
                                    st.warning(f"{admission_year}í•™ë²ˆ ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.warning("ì¡¸ì—…ìš”ê±´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                        with col_right:
                            st.subheader(f"ğŸ  ë³¸ì „ê³µ({my_primary_major}) ì´ìˆ˜ í•™ì  ê¸°ì¤€")
                            
                            if my_primary_major != "ì„ íƒ ì•ˆ í•¨" and 'primary_req' in ALL_DATA:
                                pri_data = ALL_DATA['primary_req'][ALL_DATA['primary_req']['ì „ê³µëª…'] == my_primary_major].copy()
                                
                                if not pri_data.empty:
                                    pri_data['ê¸°ì¤€í•™ë²ˆ'] = pd.to_numeric(pri_data['ê¸°ì¤€í•™ë²ˆ'], errors='coerce')
                                    pri_valid = pri_data[pri_data['ê¸°ì¤€í•™ë²ˆ'] <= admission_year]
                                    
                                    if not pri_valid.empty:
                                        matched_row = None
                                        pri_valid = pri_valid.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False)
                                        
                                        for _, p_row in pri_valid.iterrows():
                                            if selected_program in str(p_row['ì œë„ìœ í˜•']):
                                                matched_row = p_row
                                                break
                                        
                                        if matched_row is not None:
                                            st.write(f"- ë³¸ì „ê³µ ì „í•„: **{int(matched_row['ë³¸ì „ê³µ_ì „ê³µí•„ìˆ˜'])}**í•™ì ")
                                            st.write(f"- ë³¸ì „ê³µ ì „ì„ : **{int(matched_row['ë³¸ì „ê³µ_ì „ê³µì„ íƒ'])}**í•™ì ")
                                            st.markdown(f"#### ğŸ‘‰ ë³¸ì „ê³µ {int(matched_row['ë³¸ì „ê³µ_ê³„'])}í•™ì ìœ¼ë¡œ ë³€ê²½")
                                            
                                            if pd.notna(matched_row.get('ë¹„ê³ ')):
                                                st.caption(f"ì°¸ê³ : {matched_row['ë¹„ê³ ']}")
                                        else:
                                            st.info(f"ë³€ë™ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë‹¨ì¼ì „ê³µ ê¸°ì¤€ ìœ ì§€ ê°€ëŠ¥ì„±)")
                                    else:
                                        st.warning(f"{admission_year}í•™ë²ˆ ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    st.warning("ë³¸ì „ê³µ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            elif my_primary_major == "ì„ íƒ ì•ˆ í•¨":
                                st.info("ë³¸ì „ê³µì„ ì„ íƒí•˜ë©´ ë³€ë™ëœ ì´ìˆ˜ í•™ì ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                    st.divider()

                    # êµê³¼ëª© í‘œì‹œ
                    if selected_program == "ìœµí•©ì „ê³µ":
                        # ìœµí•©ì „ê³µ: ì´ìˆ˜ì²´ê³„ë„ ì´ë¯¸ì§€ + êµê³¼ëª© ëª©ë¡
                        st.subheader("ğŸ“‹ ì´ìˆ˜ì²´ê³„ë„")
                        display_curriculum_image(selected_major, selected_program)
            
                        if not COURSES_DATA.empty:
                            display_courses(selected_major, selected_program)
                    
                    elif "ì†Œë‹¨ìœ„" in selected_program or "ë§ˆì´í¬ë¡œ" in selected_program:
                        # ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬): ê³¼ì • ì•ˆë‚´ ì´ë¯¸ì§€ + êµê³¼ëª© ëª©ë¡
                        st.subheader("ğŸ–¼ï¸ ê³¼ì • ì•ˆë‚´ ì´ë¯¸ì§€")
                        display_curriculum_image(selected_major, selected_program)
            
                        if not COURSES_DATA.empty:
                            display_courses(selected_major, selected_program)
                    
                    elif selected_program == "ì—°ê³„ì „ê³µ":
                        # ì—°ê³„ì „ê³µ: êµê³¼ëª© ëª©ë¡ë§Œ
                        if not COURSES_DATA.empty:
                            display_courses(selected_major, selected_program)
                    
                    elif selected_program in ["ë³µìˆ˜ì „ê³µ", "ë¶€ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ"]:
                        # ë³µìˆ˜ì „ê³µ/ë¶€ì „ê³µ/ìœµí•©ë¶€ì „ê³µ: êµê³¼ëª© ëª©ë¡ë§Œ
                        if not COURSES_DATA.empty:
                            display_courses(selected_major, selected_program)

    elif menu == "FAQ":
        st.header("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
        
        if FAQ_DATA:
            categories = list(set([faq.get('ì¹´í…Œê³ ë¦¬', 'ì¼ë°˜') for faq in FAQ_DATA]))
            categories = [c for c in categories if c and str(c).lower() not in ['nan', 'none', '']]
            
            if not categories:
                categories = ['ì¼ë°˜']
            
            selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", ["ì „ì²´"] + sorted(categories))
            
            search_term = st.text_input("ğŸ” FAQ ê²€ìƒ‰", placeholder="í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
            
            filtered_faqs = FAQ_DATA
            
            if selected_category != "ì „ì²´":
                filtered_faqs = [faq for faq in filtered_faqs if faq.get('ì¹´í…Œê³ ë¦¬') == selected_category]
            
            if search_term:
                search_lower = search_term.lower()
                filtered_faqs = [
                    faq for faq in filtered_faqs 
                    if search_lower in faq.get('ì§ˆë¬¸', '').lower() or search_lower in faq.get('ë‹µë³€', '').lower()
                ]
            
            st.write(f"ğŸ“‹ ì´ {len(filtered_faqs)}ê°œì˜ FAQ")
            st.divider()
            
            for faq in filtered_faqs:
                with st.expander(f"**Q. {faq.get('ì§ˆë¬¸', 'ì§ˆë¬¸ ì—†ìŒ')}**"):
                    st.markdown(f"**A.** {faq.get('ë‹µë³€', 'ë‹µë³€ ì—†ìŒ')}")
        else:
            st.warning("FAQ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        st.divider()
        st.info("ğŸ’¡ ì›í•˜ëŠ” ë‹µë³€ì„ ì°¾ì§€ ëª»í•˜ì…¨ë‚˜ìš”? **AIì±—ë´‡ ìƒë‹´**ì—ì„œ ì§ì ‘ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")


# ============================================================
# ğŸš€ í”„ë¡œê·¸ë¨ ì‹¤í–‰
# ============================================================

if __name__ == "__main__":
    initialize_session_state()
    main()
